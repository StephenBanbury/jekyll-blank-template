<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-11-02T00:32:18+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Creative Reflective Journal</title><subtitle>My Creative Reflective Journal towards the Falmouth University Creative App Development Masters Degree.</subtitle><entry><title type="html">The Screen Panel Button Revisited</title><link href="http://localhost:4000/2020/11/01/screen-panel-trigger-button-2.html" rel="alternate" type="text/html" title="The Screen Panel Button Revisited" /><published>2020-11-01T00:00:00+00:00</published><updated>2020-11-01T00:00:00+00:00</updated><id>http://localhost:4000/2020/11/01/screen-panel-trigger-button-2</id><content type="html" xml:base="http://localhost:4000/2020/11/01/screen-panel-trigger-button-2.html">&lt;p&gt;I have modified the screen panel’s action as a &lt;em&gt;‘button’&lt;/em&gt;. Further modification, functionality and refinement to come…&lt;/p&gt;

&lt;p&gt;A problem up until this point in time has been the tendency for the screens to react to the present of the players’ hand in its collider when this has not been the desired effect, such as just getting the way of the screens as they move due to animation of formation changes.&lt;/p&gt;

&lt;p&gt;I have now added the need to use specific hands in combination with the controller buttons in order to trigger specific actions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Left hand + left trigger = random screen formation change&lt;/li&gt;
  &lt;li&gt;Right hand _ right trigger = random video clip selection&lt;/li&gt;
  &lt;li&gt;Left + right hands + left + right triggers = allow the player to exit the scene through the screen.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The latter option raises the screen’s mesh collider, thus allowing the player to pass through. This is written into a coroutine and allows 3 seconds before the ‘door’ is closed again and access is once again denied.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NB&lt;/strong&gt; raising of the collider is because my initial attempts to disable it did not work, due to this also having the effect of disabling the script itself, thus preventing the completion of the coroutine, leaving the gateway open and rendering any further activity attached to the screen impossible. Raising and lowering the collider simply moves it out of the way temporarily, in the manner of a portcullis!&lt;/p&gt;</content><author><name></name></author><summary type="html">I have modified the screen panel’s action as a ‘button’. Further modification, functionality and refinement to come…</summary></entry><entry><title type="html">Streaming And Displaying Video Clips</title><link href="http://localhost:4000/2020/10/31/streaming-video-clips.html" rel="alternate" type="text/html" title="Streaming And Displaying Video Clips" /><published>2020-10-31T00:00:00+00:00</published><updated>2020-10-31T00:00:00+00:00</updated><id>http://localhost:4000/2020/10/31/streaming-video-clips</id><content type="html" xml:base="http://localhost:4000/2020/10/31/streaming-video-clips.html">&lt;h1 id=&quot;partial-solution-1&quot;&gt;Partial Solution 1&lt;/h1&gt;

&lt;p&gt;I have discovered that video files can be streamed from &lt;strong&gt;&lt;a href=&quot;https://www.dropbox.com/&quot;&gt;Dropbox&lt;/a&gt;&lt;/strong&gt; if the URL is ameneded slightly. The URL is accessed by using the &lt;strong&gt;dropbox&lt;/strong&gt; ‘share’ function from the right-click on the file.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Change &lt;em&gt;‘www.dropbox.com’&lt;/em&gt; to &lt;em&gt;‘dl.dropbox.com’&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Remove the querystring _‘?dl=0’&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;NB&lt;/strong&gt; the URL is automatically modified by dropbox from to &lt;em&gt;dl.dropboxusercontent.com&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;I have added a service class that reads a locally-stored text file listing the dropbox URLs (they are amended according to the above rules if necessary).&lt;/p&gt;

&lt;p&gt;I would dearly love to place this file in the &lt;strong&gt;dropbox&lt;/strong&gt; folder and read it from there. This will allow the students to add files to the folder and then amend the text file in order for it to be included. However, the &lt;strong&gt;dropbox&lt;/strong&gt; API is not as straightforward as I would have liked. There is a SDK for .&lt;strong&gt;NET&lt;/strong&gt;, but it does not work with Unity (ref).&lt;/p&gt;

&lt;p&gt;It would, of course be possible to spend some time building a bespoke method to access the dropbox API, but I’m concerned about the amount of time this would take.&lt;/p&gt;

&lt;h1 id=&quot;partial-solution-2&quot;&gt;Partial Solution 2&lt;/h1&gt;

&lt;p&gt;Taking the dropbox plan and running with it, I have created a &lt;strong&gt;&lt;em&gt;Firebase&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;Realtime Database&lt;/em&gt; to store the URLs for the videos. I have then implemented a &lt;strong&gt;&lt;em&gt;REST API&lt;/em&gt;&lt;/strong&gt; client in order to access them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NB&lt;/strong&gt; &lt;em&gt;The reason for the REST is that I have previously had problems getting Firebase’s Unity SDK to work with Android. I believe that, at the time, it was not compatible, but current research, and the SDK’s documentation, seems to suggest that (&lt;a href=&quot;https://firebase.google.com/docs/unity/setup&quot;&gt;Android has now been incorporated&lt;/a&gt;). However, as I know that the Rest API works, for the time being I will use this.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For the time being, students will need to access the &lt;em&gt;shared link&lt;/em&gt; from Dropbox for each video, pass it on to me and I will place it in the database.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The important and urgent thing&lt;/strong&gt; is that the students can use their own content, so this solution will be very welcome as it enables this. Further development will include provision for the students to upload and to manage the database themselves.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\create-dropbox-link.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Partial Solution 1</summary></entry><entry><title type="html">VR And Social Media</title><link href="http://localhost:4000/2020/10/29/vr-and-social-media.html" rel="alternate" type="text/html" title="VR And Social Media" /><published>2020-10-29T00:00:00+00:00</published><updated>2020-10-29T00:00:00+00:00</updated><id>http://localhost:4000/2020/10/29/vr-and-social-media</id><content type="html" xml:base="http://localhost:4000/2020/10/29/vr-and-social-media.html">&lt;h1 id=&quot;i-had-an-interesting-experience-today&quot;&gt;I had an interesting experience today…&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Not for the first time…&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I posted on the Discord channel about it:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I went into my VR space today for work, as I do, and the director was in there  having a look around. It’s really interesting - there is a lot of talk of VR social media, but not a lot (I think) of direct 1-to-1 conversation in VR. It felt so natural, and surreal, to find myself in the space I’ve been creating and just randomly bumping into someone who I could see, shake hands with, have a chat with and throw a ball around. It’s the phone of the future. Who needs VR social media and mixing with total strangers? If everyone has a headset then we can all call round for a coffee, a chat and a game of tiddlewinks whenever we like, with our closest mates or just about anyone. I think this is where we’ll all end up - lying in bed while chatting with a mate we’ve never met in the flesh, drinking Earl Grey and playing backgammon while hanging out, equally comfortable in a totally fictitious place as on the top of Everest.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It may be a bit idealistic, and it came out of a frivolous and playful, albeit short and unexpected, moment. But that is also the point! Why not? The internet is the phone of the future. The mobile divice is one means to make the internet the phone of the future. VR takes this a step further.&lt;/p&gt;

&lt;p&gt;Fun though it can be, whereas there is a lot of excitement and movement in the world of social media towards the use of VR for hanging out much as you might do in a party, hoping to meet some stranger, perhaps making friends for life or experiencing a brief and (hopefully) passing acquaintence, there seems to be little catering for what I just experienced - that is, simply the potential for settling down for a chat with someone you know - in real, or virtual, life (in this case, I really have never met them in the flesh).&lt;/p&gt;

&lt;h1 id=&quot;feedback-immediacy&quot;&gt;Feedback Immediacy&lt;/h1&gt;

&lt;p&gt;This was a great way to get some immediate feedback from a primary stakeholder. Watching him use the space, taking in the updates for the first time, and discussing his thoughts with me having had no time to ponder or to frame them. As a supplimentary form of feedback and user-testing, this is very interesting and very useful.&lt;/p&gt;

&lt;p&gt;I had the same experience when accidentally stumbling upon a bunch of around five students experiencing the VR space for the first time. The response was unforgettable - the excitement was palpable, and as a suppliment to the more formal feedback gained from the students, is very interesting and informative.&lt;/p&gt;</content><author><name></name></author><summary type="html">I had an interesting experience today…</summary></entry><entry><title type="html">To Spawn Or Not To Spawn…</title><link href="http://localhost:4000/2020/10/28/thoughts-on-spawning.html" rel="alternate" type="text/html" title="To Spawn Or Not To Spawn..." /><published>2020-10-28T00:00:00+00:00</published><updated>2020-10-28T00:00:00+00:00</updated><id>http://localhost:4000/2020/10/28/thoughts-on-spawning</id><content type="html" xml:base="http://localhost:4000/2020/10/28/thoughts-on-spawning.html">&lt;p&gt;I has been put to me that usually it is best practice to create all objects that appear within a scene directly in the Unity editor, rather than to &lt;em&gt;instantiate&lt;/em&gt; them at run-time.  A main reason behind this is that it allows collaboration to happen more easily: a model or texture artist, for instance, can do their work directly in the editor, changing, removing and adding objects with ease, whereas instantiated scenes would clearly hinder this process, as they could only work during run-time and would lose any work, unless it were somehow stored and then recreated in the instantiation code.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is a very good point!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In fact, not just the artist, but the developer can benefit from this approach, as it is often simpler to work visually using the Unity tools that it is to work in code or, as I have been doing, some hybrid of the two.&lt;/p&gt;

&lt;p&gt;The temptation, as a coder, is to use code to create everything, but perhaps this instinct should be resisited. Constants, such as scenery, can be created in the editor; players, characters, objects that have ‘life’, can be spawned.&lt;/p&gt;

&lt;h1 id=&quot;how-does-this-affect-what-i-have-done-so-far-and-what-do-i-now-need-to-do&quot;&gt;How does this affect what I have done so far and what do I now need to do?&lt;/h1&gt;

&lt;p&gt;In the current context, this means some re-working. For example,  the advantage of my spawning approach is that I have the data on the objects that have been added to the scene, which is essential, for example, when animating the screens between one formation and another. I need to look at this the &lt;em&gt;other way around&lt;/em&gt;. Instead of creating the screens from the stored data, I now perhaps need to gather the positional data from the physical screens and store that for future reference.&lt;/p&gt;

&lt;p&gt;This means a significant amount of refactoring lies ahead. Pragmatically, it may be best to approach this via a &lt;em&gt;‘half-way-house’&lt;/em&gt;, where the congruence between the physical models and their data is taken for granted, simply due to the fact that their physical existence is purely due to their having been created directly from this data in the first instance! The problems that will start to creep in will be due to any divergance between the stored data and the physical entities that no longer have an inseperable relationship. As such, then, I see this being a gradual process.&lt;/p&gt;

&lt;h1 id=&quot;why-change-at-all&quot;&gt;Why change at all?&lt;/h1&gt;

&lt;p&gt;Good question! If accepted to usually be best practice in the context of working in Unity, particularly with potential collaborators, then moving forward this is something I need to consider for future projects, and this is a good time to get started.&lt;/p&gt;

&lt;h1 id=&quot;are-my-screens-characters&quot;&gt;Are my screens ‘characters’?&lt;/h1&gt;

&lt;p&gt;As I have mentioned above, scenery can be built in the editor. However, objects such as players and characters that come and go can be spawned. The question that is begging is, are my screens more analogous to scenery or player-characters? As &lt;em&gt;actional objects&lt;/em&gt;, they certainly do not remain static and are affected and controlled by the players. Their data and vital statistics are essential to their function and appearance over time.&lt;/p&gt;

&lt;p&gt;If you were to create a game along the lines of Lillyput, where the players and AI characters were living on the stomach of a massive giant, who wakes up and causes all kinds of mayhem, would the scenary be instantiated or built statically in the editor? A bit of both, I’d suggest. From a developer/creator’s point of view, it’s a balance that needs to be given serious thought in every scenario.&lt;/p&gt;

&lt;p&gt;I’m going to have to think about this. I am starting to come full circle and beginning to think of these formations as prime candidates for spawning.&lt;/p&gt;

&lt;p&gt;Whatever the outcome in this case, the point still stands that not everything needs to be instantiated, and that only certain, very specific types of objects need the kind of fine controlling that requires a process of spawning into the environment.&lt;/p&gt;</content><author><name></name></author><summary type="html">I has been put to me that usually it is best practice to create all objects that appear within a scene directly in the Unity editor, rather than to instantiate them at run-time. A main reason behind this is that it allows collaboration to happen more easily: a model or texture artist, for instance, can do their work directly in the editor, changing, removing and adding objects with ease, whereas instantiated scenes would clearly hinder this process, as they could only work during run-time and would lose any work, unless it were somehow stored and then recreated in the instantiation code.</summary></entry><entry><title type="html">Problems With Teleportation</title><link href="http://localhost:4000/2020/10/27/multi-space-4.html" rel="alternate" type="text/html" title="Problems With Teleportation" /><published>2020-10-27T00:00:00+00:00</published><updated>2020-10-27T00:00:00+00:00</updated><id>http://localhost:4000/2020/10/27/multi-space-4</id><content type="html" xml:base="http://localhost:4000/2020/10/27/multi-space-4.html">&lt;h1 id=&quot;problems-with-teleporting-the-player&quot;&gt;Problems with teleporting the player&lt;/h1&gt;

&lt;p&gt;I have been having great difficulty with the function of teleportation of the Oculus PlayerController from one space/scene to another.&lt;/p&gt;

&lt;p&gt;I would have thought that would be reasonably straightforward, in the same way as it is for spawning inanimate objects, such as screens and selection panels, by simply changing the transform associated with the player. I have set up spawn points and placed these within the individual scenes, then attempted to take their Vector3 positions and applied them to the player’s. However, I end up moving in an outrageous manner, often ending up outside the area of the scenes, or even off the floor panel altogether, leading the player to end up in freefall.&lt;/p&gt;

&lt;p&gt;I have attempted placing the player within an empty GameObject, as well as stand-alone, but the same result ensues.&lt;/p&gt;

&lt;p&gt;This has been immensely frustrating.&lt;/p&gt;

&lt;h1 id=&quot;figured-out-the-issue-to-an-extent-but-do-not-have-a-solution&quot;&gt;Figured out the issue (to an extent) but do not have a solution&lt;/h1&gt;

&lt;p&gt;I set up a marker - a red capsule - and instead of applying the spawn point positions to the Player, I applied them to the marker. The marker moved around the environment perfectly and as should be expected! So the problem is with the player.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;‘Spawning’ the player&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-method1.JPG&quot; alt=&quot;SpawnPlayer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is what it looks like in the environment with scenes. You can that sometimes the player is just shifted a few feet, other times the player is moved much further, but nowhere near the spawn point, and even off the floor plane.&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\spawnplayer-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Here you can see quite clearly the layout of the environment with no screens to obscure it&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\spawnplayer-2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;‘Spawning’ the marker&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-method2.JPG&quot; alt=&quot;SpawnMarker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here you can the red marker - which is a simple 3D object with no VR special characteristics - move and spawn as expected, whereas the VR player gets pushed around in an apparently random fashion.&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\spawnmarker-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\spawnmarker-2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;I experimented with using the Normcore VR Player, which is simply an avatar with the Normcore Realtime components attached to allow it to work in multiplayer, and is cloned during game-play, and the ‘regular’, local player, that contains the camera rig (so naturally, that would appear to be one to use).&lt;/p&gt;

&lt;p&gt;I also deactivated the Normcore-enabled player / avatar set-up altogether, and tried out a simple, basic, vanilla Oculus OVR PlayerController. This had exactly the same effect.&lt;/p&gt;

&lt;p&gt;To illustrate what is going on: -&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The spawn point’s location, where the player is supposed to be positioned (0, 1, 20)&lt;/strong&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-error-inspector-2.JPG&quot; alt=&quot;Error1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The values being applied to the player’s transform (-0.8, 0.4, 20.2) - near enough to the spawnpoint’s exact location&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-error-console-1.JPG&quot; alt=&quot;Error2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The location the player actually ends up! (39.8, 0, -20.8). Go figure!&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-error-inspector-1.JPG&quot; alt=&quot;Error3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;The x coordinate is way, way out! How can this be?!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It’s difficult to know where to go next with this! I wonder if it would be worth considering attaching the player to another object and using motion to move it to another space - as simple repositioning of a containing object had the same erroneous effect.&lt;/p&gt;

&lt;p&gt;First port of call, though, will be to research, to try to find something about this online.&lt;/p&gt;

&lt;p&gt;As The Terminator once famously said, &lt;strong&gt;I’ll be back…&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Problems with teleporting the player</summary></entry><entry><title type="html">Actions</title><link href="http://localhost:4000/2020/10/25/multi-space-3.html" rel="alternate" type="text/html" title="Actions" /><published>2020-10-25T00:00:00+01:00</published><updated>2020-10-25T00:00:00+01:00</updated><id>http://localhost:4000/2020/10/25/multi-space-3</id><content type="html" xml:base="http://localhost:4000/2020/10/25/multi-space-3.html">&lt;h1 id=&quot;controlling-player-and-actions-within-multiple-scenes&quot;&gt;Controlling player and actions within multiple scenes&lt;/h1&gt;

&lt;p&gt;Spawning scenes, including screen formations, is just the start. How do you control the screen formations and the video projections and live video feeds for each individiual screen?&lt;/p&gt;

&lt;p&gt;One line of enquiry, and the first option I tried, instantiates the selection control panel into the same starting scene as the player. The idea would then to ensure it is instantiated in the other scenes, with the player, when the player moves into them. 
This is a method I could end up working with.&lt;/p&gt;

&lt;p&gt;Another option, and the second I am trying, is to instantiate the panel in all of the scenes (along with the audio source and lighting). The panel will probably only be visible to the player - each player can own their very own panel and show and hide it as they please (or it may end up being discarded altogether).&lt;/p&gt;

&lt;p&gt;The difficulty then, with either of these options, is to ensure that: -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;all actions cause an effect on the specific scene in which the player is situated&lt;/li&gt;
  &lt;li&gt;all effects are permiated through to the multiplayer models and then to each player instance&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;update&quot;&gt;Update&lt;/h1&gt;

&lt;p&gt;I have managed to set the screen formation animation to occur for a specific scene when the button for that formation is tapped on the panel associated with that specific scene. This is done by finding the parent scene of the selection panel and sending it to the tweening method. Remember, the tweening, along with spawning, is already able to pinpoint which scene to act upon - this has made further development - and my life - much simpler!&lt;/p&gt;

&lt;p&gt;I am now concerned that this may be difficult to translate into the multiplayer environment. This will be another stage of development in the near future.&lt;/p&gt;</content><author><name></name></author><summary type="html">Controlling player and actions within multiple scenes</summary></entry><entry><title type="html">Meet Me On The Other Side</title><link href="http://localhost:4000/2020/10/25/meet-me-on-the-other-side.html" rel="alternate" type="text/html" title="Meet Me On The Other Side" /><published>2020-10-25T00:00:00+01:00</published><updated>2020-10-25T00:00:00+01:00</updated><id>http://localhost:4000/2020/10/25/meet-me-on-the-other-side</id><content type="html" xml:base="http://localhost:4000/2020/10/25/meet-me-on-the-other-side.html">&lt;h1 id=&quot;pervasive-media-studio&quot;&gt;Pervasive Media Studio&lt;/h1&gt;

&lt;p&gt;The Pervasive Media Studio is a partnership between Watershed, UWE Bristol and University of Bristol.&lt;/p&gt;

&lt;p&gt;https://www.youtube.com/watch?v=yt0Hnxz31V0&lt;/p&gt;

&lt;p&gt;Interesting talk about VR, immersion, VR experience&lt;/p&gt;

&lt;p&gt;Opposiing concepts: Cartesian Metaphysics (Descart) / Embodied Cognition&lt;/p&gt;

&lt;p&gt;Social platofmr tent to attract social groupins that match other social contexts&lt;/p&gt;

&lt;p&gt;Altspace (19:30)&lt;/p&gt;

&lt;p&gt;Hubs by Mozilla (22.30)
    no headset required
    more about creating your own personona
    more control, build from scratch
    challenging&lt;/p&gt;</content><author><name></name></author><summary type="html">Pervasive Media Studio</summary></entry><entry><title type="html">Spawning The Screens</title><link href="http://localhost:4000/2020/10/24/multi-space-2.html" rel="alternate" type="text/html" title="Spawning The Screens" /><published>2020-10-24T00:00:00+01:00</published><updated>2020-10-24T00:00:00+01:00</updated><id>http://localhost:4000/2020/10/24/multi-space-2</id><content type="html" xml:base="http://localhost:4000/2020/10/24/multi-space-2.html">&lt;h1 id=&quot;creating-multiple-scenes-from-an-orginal-template&quot;&gt;Creating multiple scenes from an orginal template&lt;/h1&gt;

&lt;p&gt;Having given the concept of mutlple spaces some thought, where each space represents a &lt;em&gt;scene&lt;/em&gt; in the multiplayer theatre environment, it became clear that I could make use of the existing infrastructure I have already put in place (see &lt;strong&gt;&lt;a href=&quot;/2020/09/01/creating-the-screens-1.html&quot;&gt;Creating the screens 1&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&quot;/2020/09/03/creating-the-screens-2.html&quot;&gt;Creating the screens 2&lt;/a&gt;&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;This method uses a class model for each screen formation, comprising definitions for the postition and rotation of each of the sixteen screen display panels within the respective formation. This information is then used when instantiating, or &lt;em&gt;spawning&lt;/em&gt;, the formation. Animations are created by &lt;em&gt;tweening&lt;/em&gt; between the previous formation’s positioning data and that of the next formation. This has, thus far, been happening in a single location, i.e. that set in each formation’s respective model.&lt;/p&gt;

&lt;p&gt;Taking this concept and applying it to the creating of a second (or third or fourth etc.) formation, it becomes clear that the existing definitions can be used as a template, with an &lt;em&gt;offset&lt;/em&gt; applied in order to translate the positional information from the original formation to another in another place within the world space.&lt;/p&gt;

&lt;p&gt;This approach requires a set of definitions for the locations of each scene within the world space. If the original scene is set at &lt;em&gt;Vector3(0, 0, 0)&lt;/em&gt;, then the second scene can exist at &lt;em&gt;Vector3(20, 0, 0)&lt;/em&gt;, and the third at &lt;em&gt;Vector3(20, 0, 20)&lt;/em&gt; etc. 
It is then simply a case of applying this information in order to offset the original formation’s positional data. The rotations must remain the same as we do not want the screens to change direction!
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Transversing the multispace&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\transverse-multispace-2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scene position definitions within the world space&lt;/strong&gt;&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\GetScenePosition-1.JPG&quot; alt=&quot;GetScenePosition&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Screen formations, showing screen positions offset by selected scene postition&lt;/strong&gt;&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\ScreenFormationService-1.JPG&quot; alt=&quot;ScreenFormationService&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scene detail model, showing how each scene comprises a scene position in world space, a screen formation definition, and references to the actual screens that have been instantiated&lt;/strong&gt;&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\SceneDetailModel.JPG&quot; alt=&quot;SceneDetailModel&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Screen position model for each individual screen&lt;/strong&gt;&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\ScreenFormationModel.JPG&quot; alt=&quot;SceneDetailModel&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Code behind the multispace&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\multispace-code-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Creating multiple scenes from an orginal template</summary></entry><entry><title type="html">The ‘Multiverse’</title><link href="http://localhost:4000/2020/10/23/multi-space-1.html" rel="alternate" type="text/html" title="The 'Multiverse'" /><published>2020-10-23T00:00:00+01:00</published><updated>2020-10-23T00:00:00+01:00</updated><id>http://localhost:4000/2020/10/23/multi-space-1</id><content type="html" xml:base="http://localhost:4000/2020/10/23/multi-space-1.html">&lt;p&gt;&lt;img src=&quot;\images\GAM750\lightbulb.jpg&quot; alt=&quot;Lightbulb&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;thinking-about-multiple-spaces&quot;&gt;Thinking about multiple spaces&lt;/h1&gt;

&lt;p&gt;I’ve just had an interesting thought, as a respone to the problem of creating multiple &lt;em&gt;‘spaces’&lt;/em&gt;, which players can move between, at times that will be decided later.&lt;/p&gt;

&lt;p&gt;If an &lt;em&gt;‘environment’&lt;/em&gt; can be spawned as an object, and accessed through a set of methods and properties etc., then this will greatly ease the way in which a player can be ‘dropped’ into the space and interect with the objects that are present within it.&lt;/p&gt;

&lt;p&gt;In a way, this is similar to creating multiple &lt;em&gt;scenes&lt;/em&gt; in Unity, except that these exist as entities within the same single scene.  In this form, therefore, they can exploit an outward facing &lt;em&gt;interface&lt;/em&gt; in order to interact with a Master Game Controller-type object, that controls the manner of who, what, why, and where a player can exist and function, but only within the specific space that it exists.&lt;/p&gt;

&lt;h1 id=&quot;nice-theory-what-about-the-actualities&quot;&gt;Nice theory, what about the actualities?&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Negative: Could ge difficult at this stage of development, having already put much infrastructure into place.&lt;/li&gt;
  &lt;li&gt;Positive: It is actually fairly early in development terms given a longer view on the project as a whole and its potential as we move forward&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It would be a task that would include creating an interface for the space, in order to access multiple other interfaces, i.e. per method an property that is part of that space.&lt;/p&gt;

&lt;h1 id=&quot;but-no&quot;&gt;But… no!&lt;/h1&gt;

&lt;p&gt;This idea would not work - I think - because the VR experience is seen from a &lt;strong&gt;first person&lt;/strong&gt; perspective, and all code is run in a similar manner. That is, each individual instance of Unity, running in each headset, will access its own set of game objects and, on each object, a set of components. That individual is &lt;strong&gt;not&lt;/strong&gt; controlling from heaven, but from their own person… on the ground.  The &lt;em&gt;‘God’&lt;/em&gt; concept suggested above, i.e. where control is exerted down on the multispace and controlling eacn individual multiplace, could work as part of a controller interface for the use of &lt;strong&gt;Stage Managers&lt;/strong&gt; and similar roles. But this is looking too complex for this purpose and within the available time frame.&lt;/p&gt;

&lt;p&gt;Therefore, I will maintain this post as a reminder of a possible way to think of this Potential model in the future.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Spatial Audio With Normcore</title><link href="http://localhost:4000/2020/10/18/spatial-audio-with-normcore.html" rel="alternate" type="text/html" title="Spatial Audio With Normcore" /><published>2020-10-18T01:00:00+01:00</published><updated>2020-10-18T01:00:00+01:00</updated><id>http://localhost:4000/2020/10/18/spatial-audio-with-normcore</id><content type="html" xml:base="http://localhost:4000/2020/10/18/spatial-audio-with-normcore.html">&lt;h1 id=&quot;out-of-the-box-audio-appears-to-be-2d&quot;&gt;Out-of-the-box: audio appears to be 2D!&lt;/h1&gt;
&lt;p&gt;During the first realtime testing with the project’s expert stakeholders, i.e. the director and technical director, I was eager to see if audio between players is 3D / spatialised, i.e. can be used to sense distance and direction. Unfortunately, it appeared to be very much 2D and unspatialised; there was no volume roll-off - no matter how near or far apart we were from each other, the volume of the voice was constant.&lt;/p&gt;

&lt;p&gt;This is a real shame.&lt;/p&gt;

&lt;p&gt;I am now looking into possible solutions for this. I am hoping that is will be as straightforward as a simple setting somewhere, or a case of adding a 3D sound source to the VR player.&lt;/p&gt;

&lt;h1 id=&quot;testing-two-headsets-are-better-than-one&quot;&gt;Testing: two headsets are better than one&lt;/h1&gt;
&lt;p&gt;Question: How do you test this with only a single headset? 
Answer: With great difficulty!&lt;/p&gt;

&lt;p&gt;Testing multiplayer environments is not the only reason I bought a new Oculus Quest 2, but it is the main one. Or, at least, it’s a good excuse!&lt;/p&gt;

&lt;p&gt;Not only can I now experience multiplayer applicaitons with family and friends, but I can also test my own developments. Not to mention that the latest model is much faster and has a much better display, at a cheaper price point. Seemed to make sense to me!&lt;/p&gt;

&lt;p&gt;Setting up is a bit of a problem, though, because Facebook now insist that you use a FB account! It is not even possible just to use your old Oculus account - it now must be linked to a FB account, even if you continue to use it only on your current headset. Bad, bad Facebook! This means that, in order to play multiplayer, &lt;strong&gt;I need to sign in on different accounts&lt;/strong&gt;. For this reason, I set up a second FB account attached to a second user on my Android phone. I will have to log into each, separately, and use each account to log into each headset, separately. What a faff!&lt;/p&gt;

&lt;p&gt;Back to the spacial audio issue…&lt;/p&gt;

&lt;h1 id=&quot;first-port-of-call-normcore-discord-server&quot;&gt;First port of call: Normcore Discord server&lt;/h1&gt;

&lt;p&gt;[01-05-2019]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;if you’re using the built-in spatializer, then you can fix easily by changing this line in AudioOutput.cs:&lt;/p&gt;

  &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;data[sOut] = !_mute ? audioData[sIn] : 0.0f;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;just change that to this:&lt;/p&gt;

  &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;data[sOut] *= !_mute ? audioData[sIn] : 0.0f;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;the input value to that OnAudioFilterRead() is set up to be 1.0 * whatever attenuation Unity has added to the AudioSource including volume&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;[01-09-2020]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;I think in V1 I had disabled the built-in spatialization&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;[02-09-2020]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Question: How do I make the player voice 3D? (e.g. how do i make them louder the closer you are to them, and quieter when you are further away? - by default you can hear people constantly)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[02-09-2020]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;take a look at the audio source on your avatar (make sure the “spatial” slider is set to “3d”) and you can muck with the falloff values on there if you want to customize it.
Unity defaults to 2D, and the falloff range is basically “100% volume up to 5 meters, still audible 100 meters away” or something like that, so it’s definitely tuned for larger spaces.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[02-09-2020]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;if you add an audio source RealtimeAvatarVoice will detect it and use it instead of creating one
you can use SetActive, but you’ll also need to make a custom RealtimeComponent in order to synchronize the active state. Normcore doesn’t synchronize that part for you&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[04-09-2020]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;I followed your advice to add an audio source to the RealtimeAvatarVoice gameobject in order to allow the spatial blend of the player’s voice to be 3d, however its still behaving like its 2D - any idea on what could be wrong?
general/04-09-2020&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[04-09-2020]&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;if you’re on V1, try making this change:
&lt;a href=&quot;if you’re on V1, try making this change:
https://discord.com/channels/393839515074297858/393841777091543052/573241867185946680&quot;&gt;if you’re on V1, try making this change:
https://discord.com/channels/393839515074297858/393841777091543052/573241867185946680
&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">Out-of-the-box: audio appears to be 2D! During the first realtime testing with the project’s expert stakeholders, i.e. the director and technical director, I was eager to see if audio between players is 3D / spatialised, i.e. can be used to sense distance and direction. Unfortunately, it appeared to be very much 2D and unspatialised; there was no volume roll-off - no matter how near or far apart we were from each other, the volume of the voice was constant.</summary></entry></feed>