<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-07-27T23:53:33+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Creative Reflective Journal</title><subtitle>My Creative Reflective Journal towards the Falmouth University Creative App Development Masters Degree.</subtitle><entry><title type="html">Understanding WebRTC</title><link href="http://localhost:4000/2020/07/26/understanding-webrtc.html" rel="alternate" type="text/html" title="Understanding WebRTC" /><published>2020-07-26T23:00:00+01:00</published><updated>2020-07-26T23:00:00+01:00</updated><id>http://localhost:4000/2020/07/26/understanding-webrtc</id><content type="html" xml:base="http://localhost:4000/2020/07/26/understanding-webrtc.html">&lt;p&gt;As stated in the previous post, at the moment &lt;strong&gt;I feel that my time would be best spent learning about WebRTC in general, rather than  specifically as a Unity plugin&lt;/strong&gt;. Once I feel I fully understand the basics I should be able to apply them more easily to my specific Unity test-case.&lt;/p&gt;

&lt;p&gt;I have found a useful-looking half-hour-long YouTube tutorial, &lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=DvlyzDZDEq4&quot;&gt;How To Create A Video Chat App With WebRTC&lt;/a&gt;&lt;/strong&gt;. It was only published a day ago but has already received over 2,000 ‘likes’ (and only 15 thumbs-down). If nothing else, I see this as further evidence of the current, pandemic-induced social lockdown interest in the subject of peer-to-peer video chat apps.&lt;/p&gt;

&lt;p&gt;I have also placed a tutorial into my Udemy Cart and may decide to purchase it. I have 10 hours to get it at the discount price of £13.99 (reduced fro £49.99, apparently). But first I will see what the free YouTube offering is about.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;I note the many cricisms in the review/comments section that this course is out of data, is deprecated and not been updated for three years. This may be unfair, but I think I’ll just find what I need for free on YouTube etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;notes-on-setting-up-the-webrtc-project&quot;&gt;Notes on setting up the WebRTC project&lt;/h1&gt;

&lt;p&gt;Setting up the server&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;npm i express ejs socket.io&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use the &lt;a href=&quot;https://expressjs.com/&quot;&gt;Expressjs server&lt;/a&gt;: &lt;a href=&quot;https://expressjs.com/en/starter/installing.html&quot;&gt;expressjs.com/installing&lt;/a&gt;, &lt;a href=&quot;https://www.npmjs.com/package/express&quot;&gt;npm&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;use dependency ejs - templating language / view engine&lt;/li&gt;
  &lt;li&gt;use socket.io&lt;/li&gt;
  &lt;li&gt;uuid&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;npm i uuid&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;allows us to create dynamic IDs for different rooms&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;npm i –save-dev nodemon&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dynamic refreshing of server on making changes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;server.js&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const express = require ('express')
const app = express()
const server = require ('http').Server(app)
const io = require('socket.io')(server)
const { v4: uuidV4 } = require('uuid')

app.set('view engine', 'ejs')
app.use(express.static('public'))

app.get('/', (req, res) =&amp;gt; {
    res.redirect(`/${uuidV4()}`)
})

app.get('/:room', (req, res) =&amp;gt; {
    res.render('room', { roomId: req.params.room })
})

server.listen(3000)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;room.ejs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: you can use ! in a new file to generate HTML boilerplate code.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;html&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lang=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;head&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;meta&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;charset=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;meta&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;viewport&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;content=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;width=device-width, initial-scale=1.0&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;title&amp;gt;&lt;/span&gt;Document&lt;span class=&quot;nt&quot;&gt;&amp;lt;/title&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;style&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;#video-grid&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nl&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;py&quot;&gt;grid-template-columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;auto-fill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;300px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;py&quot;&gt;grid-template-rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;300px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;video&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nl&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;nl&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;nl&quot;&gt;object-fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cover&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/style&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;video-grid&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;So far we have a server that generates a random room (with a random ID) everytime localhost:3000 is called&lt;/strong&gt;. The room page contains a blank div which will hold the video.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Add joining room function to server.js&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;io.on('connection', socket =&amp;gt; {
    socket.on('join-room', (roomId, userId) =&amp;gt; {
        console.log(roomId, userId)
    })
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;roomId&lt;/strong&gt; is set as a constant in the JavaScript so is sent to the page&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script&amp;gt;
    const ROOM_ID = &quot;&amp;lt;%= roomId %&amp;gt;&quot;
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/gam750/webrtc-roomid.jpg&quot; alt=&quot;roomId sent to the page&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bring in the socket.io jasvascript code into our front end, served by our own server (server.js)&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script src=&quot;/socket.io/socket.io.js&quot; defer&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Add a script file for our own JavaScript&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script src=&quot;script.js&quot; defer&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Join room and broadcast userId to other clients&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;.. in &lt;strong&gt;script.js&lt;/strong&gt; (userId is hard-coded for now)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const socket = io('/')

socket.emit('join-room', ROOM_ID, 10)

socket.on('user-connected', userId =&amp;gt; {
    console.log('User connected: ' + userId) })
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;.. in &lt;strong&gt;server.js&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;io.on('connection', socket =&amp;gt; {
    socket.on('join-room', (roomId, userId) =&amp;gt; {
        socket.join(roomId)
        socket.to(roomId).broadcast.emit('user-connected', userId)
    })
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;When the second client joins the same room (same roomId) the first client is informed&lt;/strong&gt;
&lt;img src=&quot;/images/gam750/webrtc-join-room-1.jpg&quot; alt=&quot;joining the room&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;peerjs&quot;&gt;PeerJS&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;npm i -g peer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://peerjs.com/&quot;&gt;The PeerJS library&lt;/a&gt;&lt;/strong&gt; allows us to run a &lt;strong&gt;peer server&lt;/strong&gt;, creating connections between different users using WebRTC.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Note - I’m hoping this is not going to prove to be a difficult part of the process of setting up WebRTC for Unity.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;peerjs –port 3001&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The peer server is now runing on poer 3001, which will allow us to connect users and will give us an ID to replace the hard-coded one above.&lt;/p&gt;

&lt;p&gt;Add the following (from https://peerjs.com/) to &lt;strong&gt;room.ejs&lt;/strong&gt; (using defer to ensure running first)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script defer src=&quot;https://unpkg.com/peerjs@1.3.1/dist/peerjs.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Place the emit function (in script.js) into a function to run when connected to PeerJS&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This will provde the unique ID for the user that is connected.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;myPeer.on('open', id =&amp;gt; {
    socket.emit('join-room', ROOM_ID, id)
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Get a reference to the video grid&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const videoGrid = document.getElementById('video-grid')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;And a reference to a video&lt;/strong&gt; and mute it so we don’t hear our own voice played back to us.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const myVideo = document.createElement('video')
myVideo.muted = true;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Connect our video&lt;/strong&gt;, returns a stream (as a promise), which will be listened to by an event listener (see function addVideoStream below)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;navigator.mediaDevices.getUserMedia({
    video: true,
    audio: true
}).then(stream =&amp;gt; {
    addVideoStream(myVideo, stream)
})

Function addVideoStream(video, stream){
    video.srcObject = stream
    video.addEventListener('loadedmetadata', () =&amp;gt; {
        video.play()
    })
    videoGrid.append(video)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;On refreshing our page, we can see our video appear in our page&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Permissions will be required the first time this is run.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Allowing ourselves to be connected to by other users&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Send our current video and audio stream to the new user&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;socket.on('user-connected', userId =&amp;gt; {
    connectToNewUser(userId, stream)
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When they call back we take in their video stream - called ‘stream’ - [ call.on(‘stream’,… ] and add to our list of videos [ addVideoStream(video, userVideoStream) ]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;On close, remove the video from the page.&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function connectToNewUser(userId, stream) {
    const call = myPeer.call(userId, stream)
    const video = document.createElement('video')
    call.on('stream', userVideoStream =&amp;gt; {
        addVideoStream(video, userVideoStream)
    })
    call.on('close', () =&amp;gt; {
        video.remove()
    })
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We must listen for calls so we know if someone is calling us and then we can add them to our videos on screen.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;myPeer.on('call', call =&amp;gt; {
    call.answer(stream)
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But we need to respond&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    const video = document.createElement('video')
    call.on('stream', userVideoStream =&amp;gt; {
        addVideoStream(video, userVideoStream)
    })
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So now we can receive calls by listening to our &lt;strong&gt;on call event&lt;/strong&gt; and make calls when new users connect to our room (connectToNewUser)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finally we need to handle closing the videos better when a user disconnects&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Back in &lt;strong&gt;server.js&lt;/strong&gt;, on disconnect run another function (broadcast.emit) to send the event down to our room.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;socket.on('disconnect'), () =&amp;gt; {
    socket.to(roomId).broadcast.emit('user-disconnected', userId)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;then to pick up this event in script.js&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;socket.on('user-disconnected', userId =&amp;gt; {
    console.log(userId)
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We need to use the userId to disconnect the user&lt;/p&gt;

&lt;p&gt;We can log the callers in an object&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const peers = {}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and on connecting to new user add them to the object so they can be removed when disconnected&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;peers[userId] = call

socket.on('user-disconnected', userId =&amp;gt; {
    if(peers[userId]) peers[userId].close()
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\webrtc-javascript-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;h1 id=&quot;all-the-scripts-in-their-entirity&quot;&gt;All the scripts in their entirity&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;server.js&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const express = require ('express')
const app = express()
const server = require ('http').Server(app)
const io = require('socket.io')(server)
const { v4: uuidV4 } = require('uuid')

app.set('view engine', 'ejs')
app.use(express.static('public'))

app.get('/', (req, res) =&amp;gt; {
    res.redirect(`/${uuidV4()}`)
})

app.get('/:room', (req, res) =&amp;gt; {
    res.render('room', { roomId: req.params.room })
})

io.on('connection', socket =&amp;gt; {
    socket.on('join-room', (roomId, userId) =&amp;gt; {
        socket.join(roomId)
        socket.to(roomId).broadcast.emit('user-connected', userId)

        socket.on('disconnect', () =&amp;gt; {
            socket.to(roomId).broadcast.emit('user-disconnected', userId)
        })
    })
})

server.listen(3000)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;room.ejs&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;html&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lang=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;head&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;meta&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;charset=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;meta&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;viewport&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;content=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;width=device-width, initial-scale=1.0&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ROOM_ID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;lt;%= roomId %&amp;gt;&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;defer&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://unpkg.com/peerjs@1.3.1/dist/peerjs.min.js&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/socket.io/socket.io.js&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;defer&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;script.js&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;defer&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;title&amp;gt;&lt;/span&gt;Document&lt;span class=&quot;nt&quot;&gt;&amp;lt;/title&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;style&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;#video-grid&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nl&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;py&quot;&gt;grid-template-columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;auto-fill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;300px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;py&quot;&gt;grid-template-rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;300px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;video&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nl&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;nl&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;nl&quot;&gt;object-fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cover&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/style&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;video-grid&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;script.js&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const socket = io('/')
const videoGrid = document.getElementById('video-grid')
const myPeer = new Peer(undefined, {
    host: '/',
    port: '3001'
})
const myVideo = document.createElement('video')
myVideo.muted = true;
const peers = {}

navigator.mediaDevices.getUserMedia({
    video: true,
    audio: true
}).then(stream =&amp;gt; {
    addVideoStream(myVideo, stream)

    myPeer.on('call', call =&amp;gt; {
        call.answer(stream)
        const video = document.createElement('video')
        call.on('stream', userVideoStream =&amp;gt; {
            addVideoStream(video, userVideoStream)
        })
    })

    socket.on('user-connected', userId =&amp;gt; {
        connectToNewUser(userId, stream)
    })
})

socket.on('user-disconnected', userId =&amp;gt; {
    if(peers[userId]) peers[userId].close()
})

myPeer.on('open', id =&amp;gt; {
    socket.emit('join-room', ROOM_ID, id)
})

function connectToNewUser(userId, stream) {
    const call = myPeer.call(userId, stream)
    const video = document.createElement('video')
    call.on('stream', userVideoStream =&amp;gt; {
        addVideoStream(video, userVideoStream)
    })
    call.on('close', () =&amp;gt; {
        video.remove()
    })

    peers[userId] = call
}

function addVideoStream(video, stream){
    video.srcObject = stream
    video.addEventListener('loadedmetadata', () =&amp;gt; {
        video.play()
    })
    videoGrid.append(video)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Run with..&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm run devStart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;which runs the script in package.json&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;scripts&quot;: {
  &quot;devStart&quot;: &quot;nodemon server.js&quot;
},
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This has been an interesting and valuable lesson in peer-to-peer connectivity. I am still not sure I have much of a handle on WebRTC specifically as, unexpectedly, the project uses &lt;strong&gt;&lt;a href=&quot;https://peerjs.com/&quot;&gt;Peer JS&lt;/a&gt;&lt;/strong&gt;, an external JavaScrip library to provide an API to handle WebRTC.&lt;/p&gt;

&lt;p&gt;However, I am probably - hopefully - in a better position to attempt implementing WebRTC in a Unity project.&lt;/p&gt;</content><author><name></name></author><summary type="html">As stated in the previous post, at the moment I feel that my time would be best spent learning about WebRTC in general, rather than specifically as a Unity plugin. Once I feel I fully understand the basics I should be able to apply them more easily to my specific Unity test-case.</summary></entry><entry><title type="html">Streaming To And From Unity</title><link href="http://localhost:4000/2020/07/25/streaming-into-unity.html" rel="alternate" type="text/html" title="Streaming To And From Unity" /><published>2020-07-25T15:00:00+01:00</published><updated>2020-07-25T15:00:00+01:00</updated><id>http://localhost:4000/2020/07/25/streaming-into-unity</id><content type="html" xml:base="http://localhost:4000/2020/07/25/streaming-into-unity.html">&lt;h1 id=&quot;the-requirement&quot;&gt;The requirement&lt;/h1&gt;

&lt;p&gt;I need to find a way to take data from a device and stream it into my Unity scene.&lt;/p&gt;

&lt;p&gt;An example would be taking video from a webcam or a mobile phone camera, creating a data stream to which a Unity script can subscribe and then display the streamed video onto a texture within the scene.&lt;/p&gt;

&lt;p&gt;Another, perhaps simpler example, would be to take numeric 2D positional data, manipulated on the screen of the extertanl device, and stream that to Unity.  The data can then be used to control the position of an object within the scene.&lt;/p&gt;

&lt;p&gt;Audio would be another, allowing a stream of audio data from the external device’s microphone to enter the Unity scene and be heard by the players via the audio mixer.&lt;/p&gt;

&lt;h1 id=&quot;thinking-about-options&quot;&gt;Thinking about options&lt;/h1&gt;

&lt;p&gt;Would it be best, or feasible, to create a room in the Unity project that can access the device’s camera resources, and then to create a build for each platform - i.e. Android (can be the same build as for the Oculus quest), iOs and Windows.&lt;/p&gt;

&lt;p&gt;Or could the unity project be cloud-hosted, allowing users to connect via the internet. The cloud app would need to be able to access the device’s resources across the internet, much like Zoom or Skype etc.&lt;/p&gt;

&lt;p&gt;An alternative may be to create a web app that can run in a browser - perhaps raw JavaScript or an Angular/Vue/React etc. app, which can access the device’s resources and stream via a socket to a server. The Unity project can then connect to a socket on the server and subscribe to the datastream.&lt;/p&gt;

&lt;p&gt;Other than these options we could be looking at either a cross-platform option, like Flutter or Ionic, or multiple Native apps.&lt;/p&gt;

&lt;h1 id=&quot;random-research&quot;&gt;Random research&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://stackoverflow.com/questions/37100900/unity-processing-data-stream-from-socket&quot;&gt;StackOverflow&lt;/a&gt;&lt;/strong&gt;: Unity Processing Data Stream from Socket.  This is an interesting question asked on StackOverflow and it leads to a &lt;strong&gt;potential solution&lt;/strong&gt; for setting up a TCP client in Unity: &lt;strong&gt;&lt;a href=&quot;https://stackoverflow.com/questions/36526332/simple-socket-server-in-unity/36526634#36526634&quot;&gt;Simple socket server in Unity&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://stackoverflow.com/questions/46564222/how-to-send-and-receive-tcp-messages-while-streaming-video-unity-and-socket-ne&quot;&gt;Another on StackOverflow&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://stackoverflow.com/questions/42717713/unity-live-video-streaming/42727918#42727918&quot;&gt;And another…&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://stackoverflow.com/questions/17719541/writing-and-reading-using-socket&quot;&gt;… and guess what…&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mozilla:&lt;/strong&gt; &lt;strong&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API&quot;&gt;The WebSocket API (WebSockets)&lt;/a&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_server&quot;&gt;Writing a WebSocket server in C#&lt;/a&gt;&lt;/strong&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Another possible option could be to re-use the code already implemented in my &lt;strong&gt;&lt;a href=&quot;/2020/07/11/client-server-tutorial.html&quot;&gt;C# TCP/UDP multiplayer experiment&lt;/a&gt;&lt;/strong&gt;.  As it is basically about sending and receiving data between clients via a server, in a sense it is already all in place. I’m tempted to combine this with what I could learn from the above Mozilla WebSocket documentation and to build the solution from the ground up.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://webrtc.org/&quot;&gt;WebRTC&lt;/a&gt;&lt;/strong&gt;: I keep coming back to this - it’s potentially the all-encompassing solution, covering browser, native, Unity - both client and server, both directions possible (or so it would seem).
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/2020/07/02/webrtc.html&quot;&gt;My earlier post on WebRTC&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://microsoft.github.io/MixedReality-WebRTC/manual/gettingstarted.html&quot;&gt;Microsoft’s WebRTC project&lt;/a&gt;&lt;/strong&gt;, including a library for &lt;strong&gt;&lt;a href=&quot;https://microsoft.github.io/MixedReality-WebRTC/manual/unity/unity-integration.html&quot;&gt;Unity&lt;/a&gt;&lt;/strong&gt; and a &lt;strong&gt;&lt;a href=&quot;https://microsoft.github.io/MixedReality-WebRTC/manual/unity/helloworld-unity.html&quot;&gt;Unity tutorial&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.unity3d.com/Packages/com.unity.webrtc@2.0/manual/index.html&quot;&gt;Unity documentation&lt;/a&gt;&lt;/strong&gt;: includes links to a &lt;strong&gt;&lt;em&gt;Tutorial&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;Reference&lt;/em&gt;&lt;/strong&gt; for &lt;strong&gt;&lt;em&gt;Video&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;Audio&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;Data&lt;/em&gt;&lt;/strong&gt; streaming.
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/Unity-Technologies/UnityRenderStreaming/blob/release/1.0.0/Packages/com.unity.template.renderstreaming/Documentation~/en/tutorial.md&quot;&gt;Unity Render Streaming&lt;/a&gt;&lt;/strong&gt;: streaming video out from Unity project using &lt;strong&gt;WebRTC&lt;/strong&gt; - I’m not sure just yet how useful this could be - whether it is just from the editor or from a live build. Either way, it looks interesting.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;moving-forward&quot;&gt;Moving forward…&lt;/h1&gt;

&lt;p&gt;I have been trying to find a simple, straightforward, way of introducing WebRTC into a Unity project. However, I have had trouble whichever way I’ve turned. The Microsoft package looks interesting, but my implementation via &lt;strong&gt;NuGet&lt;/strong&gt; did not introduce the Unity sample scripts and components as described. The full package implementation (i.e. before even considering the implementation of the WebRTC scripts etc. and getting a working solution up and running) could, I suppose, be studied in detail, but it looks pretty complex and I’m not sure that spending too much of my time doing so would be time well spent as there is no certainty that the result would be successful.&lt;/p&gt;

&lt;p&gt;The Unity documentation itself is not very complete, in fact I’d characterise it as being sparce. It seems to explain snippets of code as though you already have them set up in your project, without explaining how to actually set them up in your project or give a wider context to them. It appears to be another case (I come across this fairly often) of documentation written by developers who assume you have been on the journey with them, but have been easily distracted.&lt;/p&gt;

&lt;p&gt;I also tried following the Unity Render Streaming tutorial but, less than a year on, it is already out of date. I had trouble with the latest releases being quite different in terms of file content and the resulting WebRTC templates for Unity were not in line with what was being demonstrated in the video. I’m sure there are more tutorials out there, but for now &lt;strong&gt;I feel that my time would be better spent actually learning about WebRTC in general, rather than as a Unity plugin&lt;/strong&gt;. Once I have the basics, and really understand them, I should be able to apply them more easily to my specific Unity test-case.&lt;/p&gt;</content><author><name></name></author><summary type="html">The requirement</summary></entry><entry><title type="html">Taking Stock - Sprint 1 Retrospective</title><link href="http://localhost:4000/2020/07/25/taking-stock.html" rel="alternate" type="text/html" title="Taking Stock - Sprint 1 Retrospective" /><published>2020-07-25T10:00:00+01:00</published><updated>2020-07-25T10:00:00+01:00</updated><id>http://localhost:4000/2020/07/25/taking-stock</id><content type="html" xml:base="http://localhost:4000/2020/07/25/taking-stock.html">&lt;h1 id=&quot;as-sprint-1-comes-to-a-close-what-have-i-achieved&quot;&gt;As Sprint 1 comes to a close, what have I achieved?&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;I have looked at the potential of &lt;strong&gt;&lt;a href=&quot;https://docs.unity3d.com/Manual/XR.html&quot;&gt;Unity XR plug-in framework&lt;/a&gt;&lt;/strong&gt; as a replacement for Oculus Integration, which, accoring to Unity, will be deprecated in a future release. For now, I have decided to continue using Oculus Integration as it is a framework I with which I have experience, is mature, well-documented, and is still being developed by Oculus with the very interesting inclusing of hand-tracking - potentially something that will be experimented with during this project.&lt;/li&gt;
  &lt;li&gt;I have looked at the potential of &lt;strong&gt;&lt;a href=&quot;https://docs.unity3d.com/Manual/XR.html&quot;&gt;Unity XR plug-in framework&lt;/a&gt;&lt;/strong&gt; as a replacement for Oculus Integration, which, accoring to Unity, will be deprecated in &lt;em&gt;“a future release”&lt;/em&gt;. However - &lt;strong&gt;STOP PRESS&lt;/strong&gt; - I have now installed the latest version of Unity - 2020.1 - in which it appears that the old XR integration &lt;strong&gt;has&lt;/strong&gt; been deprecated. However, it also appears that Oculus Integration &lt;strong&gt;has not&lt;/strong&gt; been replaced, but actually fits in with the new Unity framework. In fact, it appears to be very easy to integrate - I just needed to enable &lt;strong&gt;XR Plug-in Management&lt;/strong&gt; and it appears to work seamlessly with Oculus Integration! I do not need to import any XR package, as was required when using the XR plug-in in my earlier experiments. The package manager appears to be much tidyer than it was too.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Old XR Settings have now disappeared&lt;/strong&gt;
&lt;img src=&quot;\images\GAM750\unity-xr-deprecated-2020.jpg&quot; alt=&quot;Unity 2020.1 changes to XR Integration and Package Manager&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;New XR Plug-in Management&lt;/strong&gt;
&lt;img src=&quot;\images\GAM750\unity-xr-plugin-1.jpg&quot; alt=&quot;Unity 2020.1 changes to XR Integration and Package Manager&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Old vs New Package Manager&lt;/strong&gt;
&lt;img src=&quot;\images\GAM750\unity-xr-plugin-2.jpg&quot; alt=&quot;Unity 2020.1 changes to XR Integration and Package Manager&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I have tested several potential options for creating a multiplayer environment. This has enabled me to make an informed decision to use &lt;strong&gt;&lt;a href=&quot;https://normcore.io/&quot;&gt;Normcore&lt;/a&gt;&lt;/strong&gt;. Although it is relatively new and is still in beta, it has the potential to simplify the process of syncing objects and events within multiplayer environments.&lt;/li&gt;
  &lt;li&gt;I have created a player character/avatar that syncs accross all clients, including transforms and voice captured via the microphone.&lt;/li&gt;
  &lt;li&gt;I have created game objects whose transforms are synced across clients.&lt;/li&gt;
  &lt;li&gt;I have learned how to create custom components that can sync across clients, such as mesh colour.&lt;/li&gt;
  &lt;li&gt;I have created a custom component that syncs an abstract, numerical variable value across clients.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;what-do-i-still-need-to-do&quot;&gt;What do I still need to do?&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Learn how to stream data, images, video and sound from external sources into the environment where it can be displayed in realtime.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;future-research-once-all-this-has-been-achieved&quot;&gt;Future research, once all this has been achieved&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;How to separate incoming video streams for individual performers so as to place them discretely onto individually-designated displays within the VR environment.&lt;/li&gt;
  &lt;li&gt;How to separate and route individual voice data from specific players within the VR environment to
    &lt;ol&gt;
      &lt;li&gt;other players within and sharing the VR environment&lt;/li&gt;
      &lt;li&gt;performers external to the VR environment.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;How to stream video capture from within the VR environment out to external devices. This will allow an external ‘audience’ to live-view the environment via, for example, Google Cardboard devices or simply on mobile device screens.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I will add more items here as I think of them…&lt;/p&gt;</content><author><name></name></author><summary type="html">As Sprint 1 comes to a close, what have I achieved?</summary></entry><entry><title type="html">Syncing Data In Normcore 2</title><link href="http://localhost:4000/2020/07/24/normcore-7.html" rel="alternate" type="text/html" title="Syncing Data In Normcore 2" /><published>2020-07-24T00:00:00+01:00</published><updated>2020-07-24T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/24/normcore-7</id><content type="html" xml:base="http://localhost:4000/2020/07/24/normcore-7.html">&lt;h1 id=&quot;success&quot;&gt;Success!&lt;/h1&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-3.1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;The &lt;strong&gt;x&lt;/strong&gt; coordinate value from the player’s hand when within the blue oblong collider is displayed while also being passed to its model. Any changes within the model are detected by the equivalent model belonging to the other clients, the respective component is informed and the display is updated.&lt;/p&gt;

&lt;p&gt;The wonderful thing is that Normcore autogenates much of the code required to keep the models in sync. It’s then relatively straightforward to use this for your own means. I converted what I’d done to sync mesh colour as it is changed via the colour picker, but amended to sync the float value. &lt;strong&gt;The idea being that this value can be then translated into anything&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;And to celebrate..&lt;/strong&gt; we’ll throw some objects around.&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore3.2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;If only I could play with a &lt;strong&gt;real person&lt;/strong&gt; rather than myself!&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore3.3.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Success!</summary></entry><entry><title type="html">Syncing Data In Normcore 1</title><link href="http://localhost:4000/2020/07/23/normcore-6.html" rel="alternate" type="text/html" title="Syncing Data In Normcore 1" /><published>2020-07-23T00:00:00+01:00</published><updated>2020-07-23T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/23/normcore-6</id><content type="html" xml:base="http://localhost:4000/2020/07/23/normcore-6.html">&lt;p&gt;I’m setting out here to try to solve the problem of syncing abstract data between two instances in a multiplayer environment.&lt;/p&gt;

&lt;p&gt;The Normcore pattern of keeping gameobjects in sync with a model held in the datastore should, in theory, also work for simple values. Here I’m attempting to find out how to do this.&lt;/p&gt;

&lt;p&gt;I’m looking in particular at the tutorial &lt;strong&gt;&lt;a href=&quot;https://normcore.io/documentation/guides/synchronizing-your-own-data.html&quot;&gt;Synchronizing your own data with custom Realtime Components&lt;/a&gt;&lt;/strong&gt; here for some guidance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;You see the problem…&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-sync-issue-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;A RealtimeComponent keeps a game object in sync with its corresponding model in the datastore. When the game object changes, it updates the model, and when the model changes, it updates the game object to match.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I have already followed the &lt;strong&gt;&lt;a href=&quot;/2020/07/16/normcore-3.html&quot;&gt;Normcore documentation-tutorial&lt;/a&gt;&lt;/strong&gt; on changing the colour of an obect, and I hope to follow a similar pattern here. However, instead of colour, I will use an abstract numerical value. This, I hope, can be the basis of transforming any kind of data, returned from any kind of action, into any other kind of action. I may be over-egging the problem here - it may be simpler than I imagine. But this should at least be a valuable learning excercise!&lt;/p&gt;</content><author><name></name></author><summary type="html">I’m setting out here to try to solve the problem of syncing abstract data between two instances in a multiplayer environment.</summary></entry><entry><title type="html">Multiplayer Made Simple</title><link href="http://localhost:4000/2020/07/22/normcore-5.html" rel="alternate" type="text/html" title="Multiplayer Made Simple" /><published>2020-07-22T00:00:00+01:00</published><updated>2020-07-22T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/22/normcore-5</id><content type="html" xml:base="http://localhost:4000/2020/07/22/normcore-5.html">&lt;p&gt;Building a simple multiplayer is made easy in Normcore.&lt;/p&gt;

&lt;p&gt;This example uses the Oculus OVRPlayerController, but it could just as easily use any other solution, such as the Unity XR integration.&lt;/p&gt;

&lt;p&gt;A Normcore Realtime VR + Player is included in the scene and the OVRPlayerController is wired in as the Local Player variable. That’s all that is required to instantiate the avatar in each multiplayer instance!&lt;/p&gt;

&lt;p&gt;The grabbable object script is also attached to the Realtime VR + Player, and Realtime View and Realtime Transform scripts are added to the grabbable object, along with a simple script that requests ownership of the object - via its Realtime Transform component - when it is grabbed by one of the players. If the Realtime View’s ‘Owned by Creating Client’ is checked then the other player cannot gain ownership.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  private void Update()
{
    if (gameObject.GetComponent&amp;lt;OVRGrabbable&amp;gt;().isGrabbed)
    {
        //potentially clear ownership first - if owned
        _realtimeTransform.RequestOwnership();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;two-players-one-headset&quot;&gt;Two players, one headset!&lt;/h1&gt;

&lt;p&gt;Testing is a bit of a problem of course, with only one Oculus Quest (and only one developer!), both players cannot be independently moved at the same time. But it is possible to see the other player and use one’s imagination! Unfortunately, without two players it is not possible to try out throwing and catching - that would be great fun!&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-2.1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;The sound of the player’s voice is also picked up enabling lipsyncing. I will be looking at ways to stream the voice to other players.&lt;/p&gt;</content><author><name></name></author><summary type="html">Building a simple multiplayer is made easy in Normcore.</summary></entry><entry><title type="html">Normcore 2 Preview</title><link href="http://localhost:4000/2020/07/17/normcore-4.html" rel="alternate" type="text/html" title="Normcore 2 Preview" /><published>2020-07-17T00:00:00+01:00</published><updated>2020-07-17T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/17/normcore-4</id><content type="html" xml:base="http://localhost:4000/2020/07/17/normcore-4.html">&lt;p&gt;I contacted Max Weisel of the Normcore team, via their Discord server, with a question, as I was having trouble getting objects to render in the other client instance - I could just see a horizon. Max responded with the solution (ensure the build is 64bit) in a matter of minutes - very impressive! I mentioned how impressed I am with Normcore and he suggested I contact Nick Savarese - another Normcore team member - to be given access to the Normcore 2 Preview. Apparently, the transitions are significantly smoother.&lt;/p&gt;

&lt;p&gt;This I did, and Nick sent me a message followed by emails with attached Unity projects with the preview versions pre-installed. It’s great to be at the cutting edge!&lt;/p&gt;

&lt;h1 id=&quot;normcore-200-preview-1&quot;&gt;Normcore 2.0.0 Preview 1&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Heyo,&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Thanks for your interest in trying out Normcore 2.0! Most of you are on Normcore 1.0, so we’ll be rolling out Normcore 2.0 features in stages in order to make upgrading as easy as possible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The first preview build is almost identical to the Normcore 1.0 API, however it features a completely new transport system and backend. Latency will be even lower and this backend should be much more stable. We’re currently only running the 2.0 backend on our US clusters. We’ll be bringing all of our regions online in about two weeks.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you’re starting out on a fresh project with Normcore 2.0, you’ll want to import the Unity package without importing the Examples folder first. Then once the package is imported, you can reimport it again if you’d like to bring the examples into the project.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Upgrading from Normcore 1.0
Ensure your project currently compiles, leave all existing Normcore files in place, and backup your project! Then follow these instructions exactly:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Import the unitypackage and wait for it to compile once.&lt;/li&gt;
    &lt;li&gt;After the first compilation, Normcore will be added in Package Manager. Unity will recompile again, and you’ll have a ton of duplicate symbol errors.&lt;/li&gt;
    &lt;li&gt;Delete the Realtime folder under Normal, and your project will start compiling again.&lt;/li&gt;
    &lt;li&gt;All that’s left is to fix any scene or prefabs that reference Normcore components. Go to Window &amp;gt; Normcore &amp;gt; Migrate and wait a few seconds for it to complete.&lt;/li&gt;
    &lt;li&gt;Once migration finishes, you’re good to go!&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Feel free to email us if you have any questions. we’ve also created a #normcore2-preview channel on our discord!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Stay Normal!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;normcore-200-preview-8&quot;&gt;Normcore 2.0.0 Preview 8&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hey everyone,&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;We’ve now deployed the breaking backend change and have pushed an updated Unity package.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;This update also moved a few files around in the Examples folder. If you get an error while updating, please delete the Normal folder, and import the latest Unity package attached here.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you’ve previously migrated RealtimeAvatar/RealtimeAvatarManager scripts in your scenes and prefabs, we’ve moved them back to source files so people can copy them easily. You’ll need to manually migrate them back, or revert to copies of your scenes / prefabs before the migration and run the migration script again.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you’re starting out on a fresh project with Normcore 2.0, you’ll want to import the Unity package without importing the Examples folder first. Then once the package is imported, you can reimport it again if you’d like to bring the examples into the project.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;As always, feel free to email us if you have any questions or hit us up on the #normcore2-preview channel on our discord!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Best,
Nick&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">I contacted Max Weisel of the Normcore team, via their Discord server, with a question, as I was having trouble getting objects to render in the other client instance - I could just see a horizon. Max responded with the solution (ensure the build is 64bit) in a matter of minutes - very impressive! I mentioned how impressed I am with Normcore and he suggested I contact Nick Savarese - another Normcore team member - to be given access to the Normcore 2 Preview. Apparently, the transitions are significantly smoother.</summary></entry><entry><title type="html">Exploring Normcore</title><link href="http://localhost:4000/2020/07/16/normcore-3.html" rel="alternate" type="text/html" title="Exploring Normcore" /><published>2020-07-16T00:00:00+01:00</published><updated>2020-07-16T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/16/normcore-3</id><content type="html" xml:base="http://localhost:4000/2020/07/16/normcore-3.html">&lt;h1 id=&quot;exploring-normcore-via-tutorials&quot;&gt;Exploring Normcore via tutorials&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;moving body&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-sync-movement.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;avatar&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-sync-avatar.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;syncing colour&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-sync-colour.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Exploring Normcore via tutorials</summary></entry><entry><title type="html">Normcore - Feeling Good</title><link href="http://localhost:4000/2020/07/16/normcore-2.html" rel="alternate" type="text/html" title="Normcore - Feeling Good" /><published>2020-07-16T00:00:00+01:00</published><updated>2020-07-16T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/16/normcore-2</id><content type="html" xml:base="http://localhost:4000/2020/07/16/normcore-2.html">&lt;h1 id=&quot;feeling-good-about-normcore&quot;&gt;Feeling good about Normcore&lt;/h1&gt;

&lt;p&gt;Normcore has everything that I imagined I would be spending a significant amount of time building, but packaged up and ready to use. For this reason alone, it is extremely attractive as a means to building a multiplayer environment. I have so far begin exploring the idea of building my own server-client in C# and using TCP and UDP, Photon PUN 2 as an out-of-the-box solution and Mirror as a Unity-integrated and relatively simple way of wiring multiplayer clients together.&lt;/p&gt;

&lt;p&gt;The one thing that sets Normcore apart is that, simply put, it just works - or so it would seem. Particularly  with regard to VR. As a VR mutliplayer developer, the basics have already been done for you. The disadvantage, then is that, if you really do want to get to understand the mechanics of multiplayer networking, of how physics are translated from one client to another etc., these are mainly done by Normcore and it’s less likely you will learn from a deap, low-level perspective.&lt;/p&gt;

&lt;p&gt;Even so, it is still necessary to understand the model that is used by Normcore, and to understand it well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\images\GAM750\normcore-flow-1.jpg&quot; alt=&quot;Normcore data flow&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A RealtimeComponent keeps a game object in sync with its corresponding model in the datastore. When the game object changes, it updates the model, and when the model changes, it updates the game object to match. This means that in the diagram above, when Player 1 moves a game object, RealtimeTransform can set the new position on its model in the datastore. When Player 2 gets a notification that the model changed, it can update the position of the matching game object in its scene&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">Feeling good about Normcore</summary></entry><entry><title type="html">The Project - Not Near Enough</title><link href="http://localhost:4000/2020/07/15/not-near-enough.html" rel="alternate" type="text/html" title="The Project - Not Near Enough" /><published>2020-07-15T00:00:00+01:00</published><updated>2020-07-15T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/15/not-near-enough</id><content type="html" xml:base="http://localhost:4000/2020/07/15/not-near-enough.html">&lt;p&gt;&lt;strong&gt;Not Near Enough&lt;/strong&gt; is a &lt;strong&gt;&lt;a href=&quot;https://www.storyfutures.com/academy&quot;&gt;StoryFutures Academy&lt;/a&gt;&lt;/strong&gt;-funded project at Falmouth University exploring VR theatre spaces.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The brief for this project is to create an adaptable and interactive virtual theatre space where
actors and audience meet. The same space would also function as a teaching and rehearsal
space for Falmouth students and staff.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;During the past week I put together an expression of interest, resulting in an invitation from the team leaders to discuss the possibility of my working on the project. This took place on Monday, and yesterday (Tuesday) I was invited to join the project as &lt;strong&gt;VR Unity Developer&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;notes-from-initial-discussion&quot;&gt;Notes from initial discussion&lt;/h2&gt;

&lt;h1 id=&quot;brief-outline---project-background&quot;&gt;Brief outline - project background&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;StoryFutures Academy&lt;/strong&gt; - one of the government’s appointed ‘creative clusters’. Collaboration between Royal Holloway University of London and National Film and Television School, who are primaritly interested in funding and upskilling businesses and organisations in the West London area in new digital media - VR, AR, XR etc.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Train The Trainer&lt;/strong&gt; is a StoryFutures initiative as part of a funding strand offered to work with universities across the country.&lt;/li&gt;
  &lt;li&gt;Five universities have this funding - Falmouth, Hertfordshire, Abertay, UCL, Bath Spa.&lt;/li&gt;
  &lt;li&gt;The funding is, in this case, to be used for a &lt;strong&gt;‘teaching-led’&lt;/strong&gt; project.&lt;/li&gt;
  &lt;li&gt;Due to the COVID-19 pandemic, this year Falmouth University &lt;strong&gt;AMATA&lt;/strong&gt; (Academy of Music and Theatre Arts) are devising a project that is about creating for an immersive, virtual environment.&lt;/li&gt;
  &lt;li&gt;The view of the directors is that theatre, performance, acting students - those interested in live performance - are better placed to consider such spaces than film and television students, because they are used to working in spaces that happen all around, be they real or virtual.&lt;/li&gt;
  &lt;li&gt;We will be working with &lt;strong&gt;theatre and performance&lt;/strong&gt; students and &lt;strong&gt;technical theatre arts&lt;/strong&gt; students.&lt;/li&gt;
  &lt;li&gt;The students will be engaged in creating content for the environment.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;20&lt;/strong&gt; students in total: &lt;strong&gt;16&lt;/strong&gt; theatre and performance and &lt;strong&gt;4&lt;/strong&gt; technical theatre arts.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-environment&quot;&gt;The environment&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Important: the &lt;strong&gt;‘liveness’&lt;/strong&gt; and &lt;strong&gt;‘interactiveness’&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Visual concept - the &lt;strong&gt;‘varyon’&lt;/strong&gt; - morphs and moves around the audience.&lt;/li&gt;
  &lt;li&gt;As well as images of performers streamed into the environment, they would like some form of &lt;strong&gt;‘volumetric capture’&lt;/strong&gt; if possible, where the performers appear in the space as a kind of &lt;strong&gt;‘hologram’&lt;/strong&gt;, or &lt;strong&gt;‘avatar’&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;This can be incomplete, blocky or outlined etc. - i.e.  not a full perfect representation.&lt;/li&gt;
  &lt;li&gt;Audience will wear headsets&lt;/li&gt;
  &lt;li&gt;Performers streamed in via, for example, cameras or laptops.&lt;/li&gt;
  &lt;li&gt;Interested in how an audience with audience interaction might &lt;em&gt;look like&lt;/em&gt;, how would they be aware of each other’s presence, how will they interact with the space?&lt;/li&gt;
  &lt;li&gt;Audience of approximately 8-10.&lt;/li&gt;
  &lt;li&gt;One idea is to maybe pick four formations created by the screens, and the audience transitions between them via an animation, with each space being seen as an interactive ‘installation’ space.&lt;/li&gt;
  &lt;li&gt;Klaus Kruse (director) outlined possible ideas for ‘flow’ through the space(s).&lt;/li&gt;
  &lt;li&gt;Potential for audience members to split up and explore difference spaces before joining together in a joint &lt;em&gt;‘grand finale’&lt;/em&gt; / &lt;em&gt;‘communal conclusion’&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;There is an awareness of the possible limitations and realisation that not every idea may be possible, or feasible given the time and technical limitations.&lt;/li&gt;
  &lt;li&gt;The animations can be derived from the experience of the way the screens, each of which hinges onto the next, move when the space changes its shape.&lt;/li&gt;
  &lt;li&gt;It would be hoped that the audience can interact with the screens in at least one of the spaces - push, move, realign into different shapes.&lt;/li&gt;
  &lt;li&gt;Live interaction via video so the audience can see and speak with the performers - live feed.&lt;/li&gt;
  &lt;li&gt;This would also mean the space can be used as a live rehearsal space.&lt;/li&gt;
  &lt;li&gt;The audience sees the performer on the screen.&lt;/li&gt;
  &lt;li&gt;Pixelation etc. will be ‘embraced’ and become part of the aesthetic.&lt;/li&gt;
  &lt;li&gt;Students can maybe access the space via 360 degree video displayed on google cardboard via phones.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/GAM750/not-near-enough-perf-map-1.jpg&quot; alt=&quot;performance map&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;research-experimentation-dialogue-and-rd&quot;&gt;Research, experimentation, dialogue and R&amp;amp;D&lt;/h1&gt;

&lt;p&gt;This is very much a dialogue, a collaboration. There is space for me, as a developer to bring to the project. It is likely that, as theatre practitioners, the project devisers and leaders of the project have thought aobut differentely, or have ideas that are not necessarily feasible in the way they imagined them. This project is in many respects, an R&amp;amp;D project - there is a lot of research and experimentation to be done in attempting to realise something that is close to the original concepts.&lt;/p&gt;

&lt;p&gt;There is also the potential for publishing a research paper or two at the end of the project. It this stage, I see this as something I’d be interested in being invovled in.&lt;/p&gt;

&lt;h1 id=&quot;time-scale&quot;&gt;Time scale&lt;/h1&gt;

&lt;p&gt;They would like something ready and working - certainly not complete - during September, or start of October, in order to work with students within the virtual space.&lt;/p&gt;

&lt;h1 id=&quot;collaboration&quot;&gt;Collaboration&lt;/h1&gt;

&lt;p&gt;It was agreed that, should it be necessary or helpful to bring in external expertise as and when necessary, we will do so. I’m thinking potentially in terms of graphics, animations, character or environment aesthetics etc., that this could be a good thing to do.&lt;/p&gt;</content><author><name></name></author><summary type="html">Not Near Enough is a StoryFutures Academy-funded project at Falmouth University exploring VR theatre spaces.</summary></entry></feed>