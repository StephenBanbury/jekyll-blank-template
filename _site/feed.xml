<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-11-14T17:52:10+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Creative Reflective Journal</title><subtitle>My Creative Reflective Journal towards the Falmouth University Creative App Development Masters Degree.</subtitle><entry><title type="html">Persisting Multiplayer State</title><link href="http://localhost:4000/2020/11/12/persisting-multiplayer.html" rel="alternate" type="text/html" title="Persisting Multiplayer State" /><published>2020-11-12T00:00:00+00:00</published><updated>2020-11-12T00:00:00+00:00</updated><id>http://localhost:4000/2020/11/12/persisting-multiplayer</id><content type="html" xml:base="http://localhost:4000/2020/11/12/persisting-multiplayer.html">&lt;h1 id=&quot;when-players-join-late&quot;&gt;When players join late&lt;/h1&gt;
&lt;p&gt;When I first put together the multiplayer environment, I imagined that every player would begin at the same time. It did not then occur to me that some players may join later, or leave and then rejoin. Therefore, it seemed reasonable to simply ensure that each change made to the environment by an individual player, such as assigning a video to a screen, could be immediately passed to all other clients and, because all clients had been there from the start, each will experience the same results, from the same chain of successive actions, as every other client in the multiplayer environment.&lt;/p&gt;

&lt;p&gt;However, what if a player joins late? They will have missed the series of actions that has led to what the other players see in their shared environment. Only the latest action will be stored and ‘known’ about by the multiplayer engine, as only the last action is held in the Normcore datastore. The player will, therefore, only see the latest video to be added.&lt;/p&gt;

&lt;h1 id=&quot;a-standard-solution&quot;&gt;A standard solution&lt;/h1&gt;
&lt;p&gt;I considered how this could be corrected. The ‘usual’ way to deal with this would be for the joining player to query one of the existing players - without their knowledge, of course - in order to find out what screens have so far been affected. I can see that this approach would could result in certain problems and is not necessarily an ideal solution: which player would you query? Have they all been there since the start? If not, you’d need to find out which had been. Either that, or they’d all have to be updated with the full set of changes, which would be load on resources. Where would this data be stored - locally?&lt;/p&gt;

&lt;h1 id=&quot;realtimearray&quot;&gt;RealtimeArray&lt;/h1&gt;

&lt;p&gt;Normcore has a special model type that holds an &lt;strong&gt;&lt;a href=&quot;https://normcore.io/documentation/reference/serialization-realtimearray.html&quot;&gt;array of realtime models&lt;/a&gt;&lt;/strong&gt;. I’d been using realtime models so far to keep data syncronised between clients. Each model can be seen as a class model comrising a number of primative data types. The &lt;em&gt;RealtimeArray&lt;/em&gt; holds an array of such models. This is &lt;strong&gt;exactly&lt;/strong&gt; what I have been looking for!&lt;/p&gt;

&lt;p&gt;Normcore describes the RealtimeArray thus: -&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is designed to be a sequential list of models that can be modified at runtime.&lt;br /&gt;
Modifying the array sends the minimal amount of information necessary for other clients to replicate the change. The whole collection is not sent every time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The Normcore tutorial &lt;strong&gt;&lt;a href=&quot;https://normcore.io/documentation/xr-guides/creating-a-multiplayer-drawing-app.html&quot;&gt;Creating a multiplayer drawing app&lt;/a&gt;&lt;/strong&gt; demonstrates the use of a RealtimeArray. It does not use it in exactly the same way, so there is a real to fully understand the concept in order to use it in your own project, but once it had ‘clicked’, it made absolute sense.&lt;/p&gt;

&lt;p&gt;Now, if a player joins in late, they are updated with all the screen video changes that have been made from the start.
&lt;br /&gt;&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\persist-all-screens-for-connecting-player.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;There is an issue with a delay while the joining player’s environment is updated - this is not helped by the fact that, for each screen, a video has begin streaming from a remote location accessed from its URL. If the videoes were local this would be a lot quicker.&lt;/p&gt;

&lt;h1 id=&quot;realtimeset&quot;&gt;RealtimeSet&lt;/h1&gt;

&lt;p&gt;Normcore has another special model type called a &lt;strong&gt;&lt;a href=&quot;https://normcore.io/documentation/reference/serialization-realtimeset.html&quot;&gt;RealtimeSet&lt;/a&gt;&lt;/strong&gt;. This may speed up things - I will attempt to replace the RealtimeArray with the RealtimeSet in due course.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;RealtimeSet is a special model type that can be used in your own custom models. It represents an unordered collection of models. Internally this is used for things like keeping track of all RealtimeViews in the scene. If order is not important, this collection is the recommended collection to use for storing collections of models.&lt;br /&gt;
Adding or removing items sends the minimal amount of information to the server in order to perform the update on all clients. The whole collection is not sent every time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I have not yet managed to test this with live video streams from performers’ webcams, so there may be some work to be done here. But the theory is the same, so it should work with, hopefully, the minimum of tweaking.&lt;/p&gt;</content><author><name></name></author><summary type="html">When players join late When I first put together the multiplayer environment, I imagined that every player would begin at the same time. It did not then occur to me that some players may join later, or leave and then rejoin. Therefore, it seemed reasonable to simply ensure that each change made to the environment by an individual player, such as assigning a video to a screen, could be immediately passed to all other clients and, because all clients had been there from the start, each will experience the same results, from the same chain of successive actions, as every other client in the multiplayer environment.</summary></entry><entry><title type="html">Teleportation In Action</title><link href="http://localhost:4000/2020/11/09/teleportation.html" rel="alternate" type="text/html" title="Teleportation In Action" /><published>2020-11-09T00:00:00+00:00</published><updated>2020-11-09T00:00:00+00:00</updated><id>http://localhost:4000/2020/11/09/teleportation</id><content type="html" xml:base="http://localhost:4000/2020/11/09/teleportation.html">&lt;h1 id=&quot;finally-teleportation-is-working&quot;&gt;Finally! Teleportation is working&lt;/h1&gt;

&lt;p&gt;It’s taken a bit of time getting here - I estimate I &lt;a href=&quot;/2020/10/27/multi-space-4.html&quot;&gt;&lt;strong&gt;spent the best part of two days&lt;/strong&gt;&lt;/a&gt; trying to get teleportation between ‘scenes’ working - but now it’s finally up and running.&lt;/p&gt;

&lt;p&gt;The solution turned out to be fairly simple:&lt;/p&gt;

&lt;p&gt;disable both the OVRPlayerCharacter and the OVRSampleScene =&amp;gt; Move the player =&amp;gt; re-enable the OVR objects&lt;/p&gt;

&lt;p&gt;I found this only worked if enough time was allowed surrounding the various part of this series - without a delay which the actions take place, the player appears to get stuck and no teleportation happens. For this reason, &lt;strong&gt;I placed the method into a coroutine&lt;/strong&gt;, which adds a short delay after the OVR objecs have been disabled, and then another delay after the teleport itself has occured, but before the re-enabling of the OVR objects.&lt;/p&gt;

&lt;p&gt;I added a sound effect for teleportation to add to the experience. When time allows, I will look at some kind of visual effect too.. perhaps putting a ‘box’ over the player’s head for those seconds during teleportation - I could have fun with the lights and graphics inside the box!&lt;/p&gt;

&lt;h2 id=&quot;stop-press&quot;&gt;STOP PRESS!&lt;/h2&gt;

&lt;p&gt;It’s still not working correctly.&lt;/p&gt;

&lt;p&gt;I can teleport between a few scenes with no apparent problem, but then, suddenly, the next location will be outside the intended scene, i.e. not true to the coordinates given. At its worse, I could find myself some distance away from the main play ares, or even off the groung plane entirely.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Teleportation issue&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\teleportation-issue-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;h1 id=&quot;fixed&quot;&gt;Fixed!&lt;/h1&gt;

&lt;p&gt;The problem was that the player was nested within a container game object. It was this object that was being teleported to new locations, rather than the player object itself. It seems the relative coordinates of the game object, &lt;strong&gt;local&lt;/strong&gt; to the containing object, were becoming increasingly distorted the more moves that were made. Now, having removed the player from the container and applied the spawn point teleportation coordinates directly, the problem appears to have vanished.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Teleportation working&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\teleportation.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Finally! Teleportation is working</summary></entry><entry><title type="html">Testing, Agile And Immediacy</title><link href="http://localhost:4000/2020/11/02/requests-for-immediate-action.html" rel="alternate" type="text/html" title="Testing, Agile And Immediacy" /><published>2020-11-02T00:00:00+00:00</published><updated>2020-11-02T00:00:00+00:00</updated><id>http://localhost:4000/2020/11/02/requests-for-immediate-action</id><content type="html" xml:base="http://localhost:4000/2020/11/02/requests-for-immediate-action.html">&lt;p&gt;Sometimes, no matter how one tries to adhere to the on-going march of the rolling sprint process, where tasks have been planned and set out for attention in a rational and (hopefully) realistic fashion, a requirement comes in from the client/stakeholder that needs to be given full attention as a matter of urgency or, at least, as something that has been newly added to the backlog with the highest priority possible, meaning it trumps all other tasks in the &lt;em&gt;‘In Progress’&lt;/em&gt; column.&lt;/p&gt;

&lt;h1 id=&quot;continual-testing&quot;&gt;Continual testing&lt;/h1&gt;

&lt;p&gt;One could argue that these should have been thought of earlier in the planning process, and there is probably probably some truth in this. But it is not always practical or allows for the lack of time, patience or experience with Agile practice. In any case, the fact that this pushes the iterative and immediacy of agile, only goes to highlight its true worth as a development management tool! But this also shows one of the benefits of continual &lt;em&gt;testing&lt;/em&gt; during development. Again, normally one would add the results of testing to tasks for the next sprint, but this is not always feasible. In this case, this is because the product is being used in a real and practical sense by the students, and time is against them as much as it is against me, as developer!&lt;/p&gt;

&lt;h1 id=&quot;requests-turned-around-in-no-time&quot;&gt;Requests turned around in no time&lt;/h1&gt;

&lt;p&gt;This morning I received a request for: -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;numbers above the screens to help students with their selections and avoid a sense of randomness&lt;/li&gt;
  &lt;li&gt;video displays to be turned 90 degrees, in an attempt to prevent the elongation resulting from the video clips being stretched in order to fit the tall screen displays. The idea is that if they are tilted on their side, live and recorded content can be done with the freedom to also tilt cameras and videa can then be ‘projected’ onto the screens with the tilt corrected. I have yet to be convinced this will work!&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These two requests were actioned very quickly and added to the release of the latest build, which contains the multispace, video streaming and screen trigger work done over the past week. If nothing else, turning things around this quickly helps with the building of trust between developer and stakeholder.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Multi-space, screen triggers, video streaming, screen numbers and alternative screen orientation&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\multispace-triggers-numbers-2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Sometimes, no matter how one tries to adhere to the on-going march of the rolling sprint process, where tasks have been planned and set out for attention in a rational and (hopefully) realistic fashion, a requirement comes in from the client/stakeholder that needs to be given full attention as a matter of urgency or, at least, as something that has been newly added to the backlog with the highest priority possible, meaning it trumps all other tasks in the ‘In Progress’ column.</summary></entry><entry><title type="html">The Screen Panel Button Revisited</title><link href="http://localhost:4000/2020/11/01/screen-panel-trigger-button-2.html" rel="alternate" type="text/html" title="The Screen Panel Button Revisited" /><published>2020-11-01T00:00:00+00:00</published><updated>2020-11-01T00:00:00+00:00</updated><id>http://localhost:4000/2020/11/01/screen-panel-trigger-button-2</id><content type="html" xml:base="http://localhost:4000/2020/11/01/screen-panel-trigger-button-2.html">&lt;p&gt;I have modified the screen panel’s action as a &lt;em&gt;‘button’&lt;/em&gt;. Further modification, functionality and refinement to come…&lt;/p&gt;

&lt;p&gt;A problem up until this point in time has been the tendency for the screens to react to the present of the players’ hand in its collider when this has not been the desired effect, such as just getting the way of the screens as they move due to animation of formation changes.&lt;/p&gt;

&lt;p&gt;I have now added the need to use specific hands in combination with the controller buttons in order to trigger specific actions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Left hand + left trigger = random screen formation change&lt;/li&gt;
  &lt;li&gt;Right hand + right trigger = random video clip selection&lt;/li&gt;
  &lt;li&gt;Left, right or both hands + left + right triggers =  open a portal allowing the player to exit the scene through the screen.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The latter option raises the screen’s mesh collider, thus allowing the player to pass through. This is written into a coroutine and allows 3 seconds before the ‘door’ is closed again and access is once again denied.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NB&lt;/strong&gt; raising of the collider is because my initial attempts to disable it did not work, due to this also having the effect of disabling the script itself, thus preventing the completion of the coroutine, leaving the gateway open and rendering any further activity attached to the screen impossible. Raising and lowering the collider simply moves it out of the way temporarily, in the manner of a portcullis!&lt;/p&gt;</content><author><name></name></author><summary type="html">I have modified the screen panel’s action as a ‘button’. Further modification, functionality and refinement to come…</summary></entry><entry><title type="html">Streaming And Displaying Video Clips</title><link href="http://localhost:4000/2020/10/31/streaming-video-clips.html" rel="alternate" type="text/html" title="Streaming And Displaying Video Clips" /><published>2020-10-31T00:00:00+00:00</published><updated>2020-10-31T00:00:00+00:00</updated><id>http://localhost:4000/2020/10/31/streaming-video-clips</id><content type="html" xml:base="http://localhost:4000/2020/10/31/streaming-video-clips.html">&lt;h1 id=&quot;partial-solution-1&quot;&gt;Partial Solution 1&lt;/h1&gt;

&lt;p&gt;I have discovered that video files can be streamed from &lt;strong&gt;&lt;a href=&quot;https://www.dropbox.com/&quot;&gt;Dropbox&lt;/a&gt;&lt;/strong&gt; if the URL is ameneded slightly. The URL is accessed by using the &lt;strong&gt;dropbox&lt;/strong&gt; ‘share’ function from the right-click on the file.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Change &lt;em&gt;‘www.dropbox.com’&lt;/em&gt; to &lt;em&gt;‘dl.dropbox.com’&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Remove the querystring _‘?dl=0’&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;NB&lt;/strong&gt; the URL is automatically modified by dropbox from to &lt;em&gt;dl.dropboxusercontent.com&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;I have added a service class that reads a locally-stored text file listing the dropbox URLs (they are amended according to the above rules if necessary).&lt;/p&gt;

&lt;p&gt;I would dearly love to place this file in the &lt;strong&gt;dropbox&lt;/strong&gt; folder and read it from there. This will allow the students to add files to the folder and then amend the text file in order for it to be included. However, the &lt;strong&gt;dropbox&lt;/strong&gt; API is not as straightforward as I would have liked. There is a SDK for .&lt;strong&gt;NET&lt;/strong&gt;, but it does not work with Unity (ref).&lt;/p&gt;

&lt;p&gt;It would, of course be possible to spend some time building a bespoke method to access the dropbox API, but I’m concerned about the amount of time this would take.&lt;/p&gt;

&lt;h1 id=&quot;partial-solution-2&quot;&gt;Partial Solution 2&lt;/h1&gt;

&lt;p&gt;Taking the dropbox plan and running with it, I have created a &lt;strong&gt;&lt;em&gt;Firebase&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;Realtime Database&lt;/em&gt; to store the URLs for the videos. I have then implemented a &lt;strong&gt;&lt;em&gt;REST API&lt;/em&gt;&lt;/strong&gt; client in order to access them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NB&lt;/strong&gt; &lt;em&gt;The reason for the REST is that I have previously had problems getting Firebase’s Unity SDK to work with Android. I believe that, at the time, it was not compatible, but current research, and the SDK’s documentation, seems to suggest that (&lt;a href=&quot;https://firebase.google.com/docs/unity/setup&quot;&gt;Android has now been incorporated&lt;/a&gt;). However, as I know that the Rest API works, for the time being I will use this.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For the time being, students will need to access the &lt;em&gt;shared link&lt;/em&gt; from Dropbox for each video, pass it on to me and I will place it in the database.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The important and urgent thing&lt;/strong&gt; is that the students can use their own content, so this solution will be very welcome as it enables this. Further development will include provision for the students to upload and to manage the database themselves.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\create-dropbox-link.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Partial Solution 1</summary></entry><entry><title type="html">VR And Social Media</title><link href="http://localhost:4000/2020/10/29/vr-and-social-media.html" rel="alternate" type="text/html" title="VR And Social Media" /><published>2020-10-29T00:00:00+00:00</published><updated>2020-10-29T00:00:00+00:00</updated><id>http://localhost:4000/2020/10/29/vr-and-social-media</id><content type="html" xml:base="http://localhost:4000/2020/10/29/vr-and-social-media.html">&lt;h1 id=&quot;i-had-an-interesting-experience-today&quot;&gt;I had an interesting experience today…&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Not for the first time…&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I posted on the Discord channel about it:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I went into my VR space today for work, as I do, and the director was in there  having a look around. It’s really interesting - there is a lot of talk of VR social media, but not a lot (I think) of direct 1-to-1 conversation in VR. It felt so natural, and surreal, to find myself in the space I’ve been creating and just randomly bumping into someone who I could see, shake hands with, have a chat with and throw a ball around. It’s the phone of the future. Who needs VR social media and mixing with total strangers? If everyone has a headset then we can all call round for a coffee, a chat and a game of tiddlewinks whenever we like, with our closest mates or just about anyone. I think this is where we’ll all end up - lying in bed while chatting with a mate we’ve never met in the flesh, drinking Earl Grey and playing backgammon while hanging out, equally comfortable in a totally fictitious place as on the top of Everest.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It may be a bit idealistic, and it came out of a frivolous and playful, albeit short and unexpected, moment. But that is also the point! Why not? The internet is the phone of the future. The mobile divice is one means to make the internet the phone of the future. VR takes this a step further.&lt;/p&gt;

&lt;p&gt;Fun though it can be, whereas there is a lot of excitement and movement in the world of social media towards the use of VR for hanging out much as you might do in a party, hoping to meet some stranger, perhaps making friends for life or experiencing a brief and (hopefully) passing acquaintence, there seems to be little catering for what I just experienced - that is, simply the potential for settling down for a chat with someone you know - in real, or virtual, life (in this case, I really have never met them in the flesh).&lt;/p&gt;

&lt;h1 id=&quot;feedback-immediacy&quot;&gt;Feedback Immediacy&lt;/h1&gt;

&lt;p&gt;This was a great way to get some immediate feedback from a primary stakeholder. Watching him use the space, taking in the updates for the first time, and discussing his thoughts with me having had no time to ponder or to frame them. As a supplimentary form of feedback and user-testing, this is very interesting and very useful.&lt;/p&gt;

&lt;p&gt;I had the same experience when accidentally stumbling upon a bunch of around five students experiencing the VR space for the first time. The response was unforgettable - the excitement was palpable, and as a suppliment to the more formal feedback gained from the students, is very interesting and informative.&lt;/p&gt;</content><author><name></name></author><summary type="html">I had an interesting experience today…</summary></entry><entry><title type="html">To Spawn Or Not To Spawn…</title><link href="http://localhost:4000/2020/10/28/thoughts-on-spawning.html" rel="alternate" type="text/html" title="To Spawn Or Not To Spawn..." /><published>2020-10-28T00:00:00+00:00</published><updated>2020-10-28T00:00:00+00:00</updated><id>http://localhost:4000/2020/10/28/thoughts-on-spawning</id><content type="html" xml:base="http://localhost:4000/2020/10/28/thoughts-on-spawning.html">&lt;p&gt;I has been put to me that usually it is best practice to create all objects that appear within a scene directly in the Unity editor, rather than to &lt;em&gt;instantiate&lt;/em&gt; them at run-time.  A main reason behind this is that it allows collaboration to happen more easily: a model or texture artist, for instance, can do their work directly in the editor, changing, removing and adding objects with ease, whereas instantiated scenes would clearly hinder this process, as they could only work during run-time and would lose any work, unless it were somehow stored and then recreated in the instantiation code.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is a very good point!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In fact, not just the artist, but the developer can benefit from this approach, as it is often simpler to work visually using the Unity tools that it is to work in code or, as I have been doing, some hybrid of the two.&lt;/p&gt;

&lt;p&gt;The temptation, as a coder, is to use code to create everything, but perhaps this instinct should be resisited. Constants, such as scenery, can be created in the editor; players, characters, objects that have ‘life’, can be spawned.&lt;/p&gt;

&lt;h1 id=&quot;how-does-this-affect-what-i-have-done-so-far-and-what-do-i-now-need-to-do&quot;&gt;How does this affect what I have done so far and what do I now need to do?&lt;/h1&gt;

&lt;p&gt;In the current context, this means some re-working. For example,  the advantage of my spawning approach is that I have the data on the objects that have been added to the scene, which is essential, for example, when animating the screens between one formation and another. I need to look at this the &lt;em&gt;other way around&lt;/em&gt;. Instead of creating the screens from the stored data, I now perhaps need to gather the positional data from the physical screens and store that for future reference.&lt;/p&gt;

&lt;p&gt;This means a significant amount of refactoring lies ahead. Pragmatically, it may be best to approach this via a &lt;em&gt;‘half-way-house’&lt;/em&gt;, where the congruence between the physical models and their data is taken for granted, simply due to the fact that their physical existence is purely due to their having been created directly from this data in the first instance! The problems that will start to creep in will be due to any divergance between the stored data and the physical entities that no longer have an inseperable relationship. As such, then, I see this being a gradual process.&lt;/p&gt;

&lt;h1 id=&quot;why-change-at-all&quot;&gt;Why change at all?&lt;/h1&gt;

&lt;p&gt;Good question! If accepted to usually be best practice in the context of working in Unity, particularly with potential collaborators, then moving forward this is something I need to consider for future projects, and this is a good time to get started.&lt;/p&gt;

&lt;h1 id=&quot;are-my-screens-characters&quot;&gt;Are my screens ‘characters’?&lt;/h1&gt;

&lt;p&gt;As I have mentioned above, scenery can be built in the editor. However, objects such as players and characters that come and go can be spawned. The question that is begging is, are my screens more analogous to scenery or player-characters? As &lt;em&gt;actional objects&lt;/em&gt;, they certainly do not remain static and are affected and controlled by the players. Their data and vital statistics are essential to their function and appearance over time.&lt;/p&gt;

&lt;p&gt;If you were to create a game along the lines of Lillyput, where the players and AI characters were living on the stomach of a massive giant, who wakes up and causes all kinds of mayhem, would the scenary be instantiated or built statically in the editor? A bit of both, I’d suggest. From a developer/creator’s point of view, it’s a balance that needs to be given serious thought in every scenario.&lt;/p&gt;

&lt;p&gt;I’m going to have to think about this. I am starting to come full circle and beginning to think of these formations as prime candidates for spawning.&lt;/p&gt;

&lt;p&gt;Whatever the outcome in this case, the point still stands that not everything needs to be instantiated, and that only certain, very specific types of objects need the kind of fine controlling that requires a process of spawning into the environment.&lt;/p&gt;</content><author><name></name></author><summary type="html">I has been put to me that usually it is best practice to create all objects that appear within a scene directly in the Unity editor, rather than to instantiate them at run-time. A main reason behind this is that it allows collaboration to happen more easily: a model or texture artist, for instance, can do their work directly in the editor, changing, removing and adding objects with ease, whereas instantiated scenes would clearly hinder this process, as they could only work during run-time and would lose any work, unless it were somehow stored and then recreated in the instantiation code.</summary></entry><entry><title type="html">Problems With Teleportation</title><link href="http://localhost:4000/2020/10/27/multi-space-4.html" rel="alternate" type="text/html" title="Problems With Teleportation" /><published>2020-10-27T00:00:00+00:00</published><updated>2020-10-27T00:00:00+00:00</updated><id>http://localhost:4000/2020/10/27/multi-space-4</id><content type="html" xml:base="http://localhost:4000/2020/10/27/multi-space-4.html">&lt;h1 id=&quot;problems-with-teleporting-the-player&quot;&gt;Problems with teleporting the player&lt;/h1&gt;

&lt;p&gt;I have been having great difficulty with the function of teleportation of the Oculus PlayerController from one space/scene to another.&lt;/p&gt;

&lt;p&gt;I would have thought that would be reasonably straightforward, in the same way as it is for spawning inanimate objects, such as screens and selection panels, by simply changing the transform associated with the player. I have set up spawn points and placed these within the individual scenes, then attempted to take their Vector3 positions and applied them to the player’s. However, I end up moving in an outrageous manner, often ending up outside the area of the scenes, or even off the floor panel altogether, leading the player to end up in freefall.&lt;/p&gt;

&lt;p&gt;I have attempted placing the player within an empty GameObject, as well as stand-alone, but the same result ensues.&lt;/p&gt;

&lt;p&gt;This has been immensely frustrating.&lt;/p&gt;

&lt;h1 id=&quot;figured-out-the-issue-to-an-extent-but-do-not-have-a-solution&quot;&gt;Figured out the issue (to an extent) but do not have a solution&lt;/h1&gt;

&lt;p&gt;I set up a marker - a red capsule - and instead of applying the spawn point positions to the Player, I applied them to the marker. The marker moved around the environment perfectly and as should be expected! So the problem is with the player.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;‘Spawning’ the player&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-method1.JPG&quot; alt=&quot;SpawnPlayer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is what it looks like in the environment with scenes. You can that sometimes the player is just shifted a few feet, other times the player is moved much further, but nowhere near the spawn point, and even off the floor plane.&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\spawnplayer-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Here you can see quite clearly the layout of the environment with no screens to obscure it&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\spawnplayer-2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;‘Spawning’ the marker&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-method2.JPG&quot; alt=&quot;SpawnMarker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here you can the red marker - which is a simple 3D object with no VR special characteristics - move and spawn as expected, whereas the VR player gets pushed around in an apparently random fashion.&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\spawnmarker-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\GAM750\spawnmarker-2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;I experimented with using the Normcore VR Player, which is simply an avatar with the Normcore Realtime components attached to allow it to work in multiplayer, and is cloned during game-play, and the ‘regular’, local player, that contains the camera rig (so naturally, that would appear to be one to use).&lt;/p&gt;

&lt;p&gt;I also deactivated the Normcore-enabled player / avatar set-up altogether, and tried out a simple, basic, vanilla Oculus OVR PlayerController. This had exactly the same effect.&lt;/p&gt;

&lt;p&gt;To illustrate what is going on: -&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The spawn point’s location, where the player is supposed to be positioned (0, 1, 20)&lt;/strong&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-error-inspector-2.JPG&quot; alt=&quot;Error1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The values being applied to the player’s transform (-0.8, 0.4, 20.2) - near enough to the spawnpoint’s exact location&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-error-console-1.JPG&quot; alt=&quot;Error2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The location the player actually ends up! (39.8, 0, -20.8). Go figure!&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;\images\GAM750\spawnpoint-error-inspector-1.JPG&quot; alt=&quot;Error3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;The x coordinate is way, way out! How can this be?!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It’s difficult to know where to go next with this! I wonder if it would be worth considering attaching the player to another object and using motion to move it to another space - as simple repositioning of a containing object had the same erroneous effect.&lt;/p&gt;

&lt;p&gt;First port of call, though, will be to research, to try to find something about this online.&lt;/p&gt;

&lt;p&gt;As The Terminator once famously said, &lt;strong&gt;I’ll be back…&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Problems with teleporting the player</summary></entry><entry><title type="html">Meet Me On The Other Side</title><link href="http://localhost:4000/2020/10/25/meet-me-on-the-other-side.html" rel="alternate" type="text/html" title="Meet Me On The Other Side" /><published>2020-10-25T00:00:00+01:00</published><updated>2020-10-25T00:00:00+01:00</updated><id>http://localhost:4000/2020/10/25/meet-me-on-the-other-side</id><content type="html" xml:base="http://localhost:4000/2020/10/25/meet-me-on-the-other-side.html">&lt;h1 id=&quot;pervasive-media-studio&quot;&gt;Pervasive Media Studio&lt;/h1&gt;

&lt;p&gt;The Pervasive Media Studio is a partnership between Watershed, UWE Bristol and University of Bristol.&lt;/p&gt;

&lt;p&gt;https://www.youtube.com/watch?v=yt0Hnxz31V0&lt;/p&gt;

&lt;p&gt;Interesting talk about VR, immersion, VR experience&lt;/p&gt;

&lt;p&gt;Opposiing concepts: Cartesian Metaphysics (Descart) / Embodied Cognition&lt;/p&gt;

&lt;p&gt;Social platofmr tent to attract social groupins that match other social contexts&lt;/p&gt;

&lt;p&gt;Altspace (19:30)&lt;/p&gt;

&lt;p&gt;Hubs by Mozilla (22.30)
    no headset required
    more about creating your own personona
    more control, build from scratch
    challenging&lt;/p&gt;</content><author><name></name></author><summary type="html">Pervasive Media Studio</summary></entry><entry><title type="html">Actions</title><link href="http://localhost:4000/2020/10/25/multi-space-3.html" rel="alternate" type="text/html" title="Actions" /><published>2020-10-25T00:00:00+01:00</published><updated>2020-10-25T00:00:00+01:00</updated><id>http://localhost:4000/2020/10/25/multi-space-3</id><content type="html" xml:base="http://localhost:4000/2020/10/25/multi-space-3.html">&lt;h1 id=&quot;controlling-player-and-actions-within-multiple-scenes&quot;&gt;Controlling player and actions within multiple scenes&lt;/h1&gt;

&lt;p&gt;Spawning scenes, including screen formations, is just the start. How do you control the screen formations and the video projections and live video feeds for each individiual screen?&lt;/p&gt;

&lt;p&gt;One line of enquiry, and the first option I tried, instantiates the selection control panel into the same starting scene as the player. The idea would then to ensure it is instantiated in the other scenes, with the player, when the player moves into them. 
This is a method I could end up working with.&lt;/p&gt;

&lt;p&gt;Another option, and the second I am trying, is to instantiate the panel in all of the scenes (along with the audio source and lighting). The panel will probably only be visible to the player - each player can own their very own panel and show and hide it as they please (or it may end up being discarded altogether).&lt;/p&gt;

&lt;p&gt;The difficulty then, with either of these options, is to ensure that: -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;all actions cause an effect on the specific scene in which the player is situated&lt;/li&gt;
  &lt;li&gt;all effects are permiated through to the multiplayer models and then to each player instance&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;update&quot;&gt;Update&lt;/h1&gt;

&lt;p&gt;I have managed to set the screen formation animation to occur for a specific scene when the button for that formation is tapped on the panel associated with that specific scene. This is done by finding the parent scene of the selection panel and sending it to the tweening method. Remember, the tweening, along with spawning, is already able to pinpoint which scene to act upon - this has made further development - and my life - much simpler!&lt;/p&gt;

&lt;p&gt;I am now concerned that this may be difficult to translate into the multiplayer environment. This will be another stage of development in the near future.&lt;/p&gt;</content><author><name></name></author><summary type="html">Controlling player and actions within multiple scenes</summary></entry></feed>