<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-07-15T15:03:05+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Creative Reflective Journal</title><subtitle>My Creative Reflective Journal towards the Falmouth University Creative App Development Masters Degree.</subtitle><entry><title type="html">Normcore</title><link href="http://localhost:4000/2020/07/13/normcore.html" rel="alternate" type="text/html" title="Normcore" /><published>2020-07-13T00:00:00+01:00</published><updated>2020-07-13T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/13/normcore</id><content type="html" xml:base="http://localhost:4000/2020/07/13/normcore.html">&lt;p&gt;This is potentially the best option of all - if I were to forgoe the build-your-own-networking-solution learning curve I mention in the &lt;strong&gt;&lt;a href=&quot;/2020/07/11/client-server-tutorial.html&quot;&gt;previous post&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Normcore looks to be self-contained, including all the building block APIs to get a fully working multiplayer up and running in a short space of time, much like Photon but, from the looks of it, even simpler to implement. It’s main attraction is that it is particularly geared toward VR/AR, which is a huge part of the work out of the way.&lt;/p&gt;

&lt;p&gt;However, it is less mature than Photon, being currently in Beta. But that makes it nice, fresh and young!&lt;/p&gt;

&lt;p&gt;It is created by &lt;strong&gt;&lt;a href=&quot;https://www.normalvr.com/&quot;&gt;normal&lt;/a&gt;&lt;/strong&gt;, who create VR games themselves. I have been particularly enthral to &lt;strong&gt;&lt;a href=&quot;https://halfandhalf.fun/&quot;&gt;Half+Half&lt;/a&gt;&lt;/strong&gt;. Normcore is the plugin they have build for themselves to build their software. It’s all explained in their &lt;strong&gt;&lt;a href=&quot;https://www.normalvr.com/blog/normcore/&quot;&gt;blog&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We’ve spent the last three years working on Normcore, a Unity plug-in for our own internal use, implementing all the different pieces—state syncing, physics syncing, voice chat, persistence, fast serialization with versioning, delta compression, flow control, and much more. Through this process, we noticed a pattern: Everyone currently needs to implement each of these pieces from scratch.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;…we’ve noticed the VR/AR community is in serious need of good multiplayer support, especially when it comes to voice chat (which we believe is paramount to achieving presence in multiplayer spaces). The VOIP community solved high-quality low-latency voice chat a long time ago, and we’ve incorporated the lessons they’ve learned into how audio works in Normcore&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So… all very, very interesting…&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">This is potentially the best option of all - if I were to forgoe the build-your-own-networking-solution learning curve I mention in the previous post.</summary></entry><entry><title type="html">Client/Server Tutorial</title><link href="http://localhost:4000/2020/07/11/client-server-tutorial.html" rel="alternate" type="text/html" title="Client/Server Tutorial" /><published>2020-07-11T00:00:00+01:00</published><updated>2020-07-11T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/11/client-server-tutorial</id><content type="html" xml:base="http://localhost:4000/2020/07/11/client-server-tutorial.html">&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLXkn83W0QkfnqsK8I0RAz5AbUxfg3bOQ5&quot;&gt;Tom Weiland C# Networking Tutorials&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This has been a very interesting tutorial. The objective is to build a console app server which connects clients and allows mutliplayer interaction.&lt;/p&gt;

&lt;p&gt;Following the tutorial and coding along are not necessarily easy bedfellows, because it is quite a complex set up. My approach is to follow what I can whilst coding and to later work out what I do not fully understand.&lt;/p&gt;

&lt;p&gt;By the end of the first five installments I have build a server, which allows clients to connect, spawning ‘player’ characters, following their movements so they can be viewed by other connected clients, and then disconnecting when a client closes down or the server closes down.&lt;/p&gt;

&lt;p&gt;After this point I feel I really need to know how to pass data across the socket connection in order to inform other clients, via the server in this case, that something has changed in one of the client’s environments. It seems I need to spawn every object that is included in any kind of interaction. This could potentially  involve lots of spawning, and then lots of data for each type of interaction, being passed across the network and then interpreted by the server before being diseminated to each client. At least, that how I believe it will require setting up, before having undertaking the course installments beyond simply moving a player character around the (so far unlimited) space.&lt;/p&gt;

&lt;p&gt;The question here is, do I need to continue exploring the console server option, in which case, do I need to use a phyics library like &lt;a href=&quot;https://www.youtube.com/redirect?event=video_description&amp;amp;v=qkjr_rv4AIQ&amp;amp;redir_token=QUFFLUhqbEpGMUgxUFpzNW4yLXJUaDVGaTFXai0zRHZMUXxBQ3Jtc0ttYWNEM2VQTHlCQWk1c1E5dXhBaUZHQVp1OTFOOTVTX0tJa1lkek45Sk9vYWJhWU1OeHZfd0Y1Y0VwYm1Jb2l3dnNSeGY2SUhPSm9MS0xqM2FJaXdLemdEeVJvNmtTZXpSU1A0Y3ViWXJpbmpuTlhlcw%3D%3D&amp;amp;q=https%3A%2F%2Fgithub.com%2Fbepu%2Fbepuphysics2&quot;&gt;BepuPhysics&lt;/a&gt;, with the alternative being to move the server code into Unity and use its in-build physics, or have I found a pathway this is actually unnecessarily complex? There is a &lt;strong&gt;lot&lt;/strong&gt; to do - I’ll need to add server-side collisions and work out how to make actions that happen on the client also happen elsewhere.&lt;/p&gt;

&lt;p&gt;Instead, &lt;strong&gt;can I find a simpler solution?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tom suggests that the reason for this setup is partly to prevent cheating. But what I am doing does not attract cheats ;). Would an alterantive such as Mirror be more appropriate? Mirror at least allows direct client-client communication once the connection has been created via the server.&lt;/p&gt;

&lt;p&gt;Or Photon PUN 2? I found this, which sees to suggest that built-in solutions could work: &lt;a href=&quot;https://sharpcoderblog.com/blog/sync-rigidbodies-over-network-using-pun-2&quot;&gt;Sync Rigidbodies Over Network Using PUN 2&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Oh.. my.. God! Why hast Thou forsaken me?!!!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Both these scenarios mean that I will be bypassing a full inward transfer of networking knowledge and plumping for a relatively easy/soft/lightweight/lazy approach. I would like to fully ‘get it’. But I have time and resource limitations. Perhaps it would be best, as is often the case it seems, to go for the simple option to get it up and running and then get to know the detail and complexity later? I’ve spent the best part of three days (i.e. evenings not spent with the family) on this tutorial… Grrrrrr!&lt;/p&gt;

&lt;h2 id=&quot;normcore&quot;&gt;Normcore&lt;/h2&gt;

&lt;p&gt;I’ve now just come across &lt;strong&gt;&lt;a href=&quot;/2020/07/13/normcore.html&quot;&gt;Normcore&lt;/a&gt;&lt;/strong&gt;. This looks to be yet another option…&lt;/p&gt;</content><author><name></name></author><summary type="html">Tom Weiland C# Networking Tutorials</summary></entry><entry><title type="html">What Is There Out There?</title><link href="http://localhost:4000/2020/07/11/what-is-there-out-there.html" rel="alternate" type="text/html" title="What Is There Out There?" /><published>2020-07-11T00:00:00+01:00</published><updated>2020-07-11T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/11/what-is-there-out-there</id><content type="html" xml:base="http://localhost:4000/2020/07/11/what-is-there-out-there.html">&lt;h1 id=&quot;here-i-am-going-to-explore-existing-apps-experiences-games-basically-anything-whatsoever-that-holds-some-level-of-interest-as-an-immersive-interactive-space-for-performance-socialisaing-creating-basically-just-being-in-a-virtual-space-with-other-people-represented-in-virtual-form&quot;&gt;Here I am going to explore existing apps, experiences, games… basically anything whatsoever… that holds some level of interest as an immersive, interactive space for performance, socialisaing, creating.. basically, just ‘being’ in a virtual space with other ‘people’ represented in virtual form.&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;The Under Presents&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Here I am going to explore existing apps, experiences, games… basically anything whatsoever… that holds some level of interest as an immersive, interactive space for performance, socialisaing, creating.. basically, just ‘being’ in a virtual space with other ‘people’ represented in virtual form.</summary></entry><entry><title type="html">Thought On Building Multiplayer</title><link href="http://localhost:4000/2020/07/05/building-multiplayer.html" rel="alternate" type="text/html" title="Thought On Building Multiplayer" /><published>2020-07-05T00:00:00+01:00</published><updated>2020-07-05T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/05/building-multiplayer</id><content type="html" xml:base="http://localhost:4000/2020/07/05/building-multiplayer.html">&lt;h2 id=&quot;unity-xr-integration--mirror&quot;&gt;Unity XR Integration &amp;amp; Mirror&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=5LhA4Tk_uvI&quot;&gt;Good Mirror totorial series, but not VR specific&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I could only get to the point that my XR Rig (i.e. my player character) could appear as multiplayer clients, but I have so far not got to the stage where each client can see the other in the same space.&lt;/p&gt;

&lt;p&gt;There is a distinct lack of documentation for using Mirror, less for XR Integration, and zero (it seems) for XR Integration multiplayer solutions!&lt;/p&gt;

&lt;p&gt;I am keen to follow this route - it is my chosen one for reasons given elsewhere - but may have to resort to older tech and methods. Rather than spend too much time figuring this particular stack out, I now intend to look into using Oculus Integration (which I already know works, from experience) and Photon (which is mature, tried and tested and is better documented than Mirror).&lt;/p&gt;

&lt;p&gt;[Video showing XR and Mirror]&lt;/p&gt;

&lt;h2 id=&quot;unity-oculus-integration--photon-pun&quot;&gt;Unity, Oculus Integration &amp;amp; Photon PUN&lt;/h2&gt;

&lt;p&gt;An old tutorial aimed at the Oculus Rift - hopefully Oculus Link will allow development to work seamlessly on the Quest: &lt;a href=&quot;https://www.youtube.com/watch?time_continue=3&amp;amp;v=CraH51-_xJo&amp;amp;feature=emb_logo&quot;&gt;Tutorial - an oldie, but hopefully a goodie!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A non-VR tutorial series on PUN 2 that is pretty comprehensive, by &lt;a href=&quot;https://www.youtube.com/watch?v=02P_mrszvzY&quot;&gt;Info Gamer&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;is-there-a-better-way&quot;&gt;Is there a better way?&lt;/h2&gt;

&lt;p&gt;Is using one solution for the multiplayer network and another for streaming data and video the best option?&lt;/p&gt;

&lt;p&gt;I’m not sure..&lt;/p&gt;

&lt;p&gt;Could something like WebRTC do it all? I assume it won’t have the specific multiplayer scripts / API included by the others, but has anyone done somthing like this? Whether it could be &lt;strong&gt;made to handle multiplayer&lt;/strong&gt; functionality may be missing the point. If it can be made to do so, &lt;strong&gt;do I have the time?&lt;/strong&gt; to implement it?
This, I doubt very much.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://webrtchacks.com/datachannel-multiplayer-game/&quot;&gt;webrtcH4cKS: ~ Gaming with the WebRTC DataChannel – A Walkthrough with Arin Sime&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/gam750/webrtc-multiplayer-1.JPG&quot; alt=&quot;WebRTC multiplayer data channel&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is an interesting discussion about using WebRTC for multiplayer games. It is possible. But this is JavaScript. Making it work for Unity is another thing entirely. The Unity package may manage everything needed, but it would take a deep dive to find out how.&lt;/p&gt;</content><author><name></name></author><summary type="html">Unity XR Integration &amp;amp; Mirror</summary></entry><entry><title type="html">Mirror</title><link href="http://localhost:4000/2020/07/02/mirror.html" rel="alternate" type="text/html" title="Mirror" /><published>2020-07-02T00:00:00+01:00</published><updated>2020-07-02T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/02/mirror</id><content type="html" xml:base="http://localhost:4000/2020/07/02/mirror.html">&lt;p&gt;This is an option I had not come across when researching multiplayer environment options back in GAM720. Most information I have found this time around seems to be quite recent, even though it appears to have originally come into being in 2016. This, to me, is a good sign, as it appears to be gaining traction and becoming more relevant as time marches on.&lt;/p&gt;

&lt;h1 id=&quot;benefits&quot;&gt;Benefits&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Open source&lt;/li&gt;
  &lt;li&gt;Free&lt;/li&gt;
  &lt;li&gt;No player limits&lt;/li&gt;
  &lt;li&gt;Good documentation&lt;/li&gt;
  &lt;li&gt;Built on the old Unity multiplayer system (UNET), bug-fixed and generally improved.&lt;/li&gt;
  &lt;li&gt;Client/Server pattern: the server can be hosted by a ‘player, who is also a client (similar to Photon)&lt;/li&gt;
  &lt;li&gt;You can also set up a dedicated server.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;useful-links&quot;&gt;Useful links&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/vis2k/Mirror/releases&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLS6sInD7ThM1aUDj8lZrF4b4lpvejB2uB&quot;&gt;Dapper Dino (YouTube)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=yRvfLLTkIXM&quot;&gt;Daniel Hampikian&lt;/a&gt;: mirror’s predecessor, unet - it’s similar enough I think.&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;With Mirror, I managed to create a multiplayer networked environment using Unity XR integration for the VR rig. 
This is an option definitely worth considering.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\mirror-networking-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;The difficulty may come when networking moving rigid bodies, collisions, object ‘ownership’ etc. I have yet to find out how troublesome, or not, this will prove to be. I believe that one of Normcore’s possible strengths is that this is made relatively straightforward. But until I get Normcore working as well as I’ve got Mirror working for something fairly simple, such as this, then Mirror is looking a good bet. It’s a similar story for Photon PUN 2, which I’ve yet to see working and working well in a VR environment.&lt;/p&gt;

&lt;p&gt;The research continues…&lt;/p&gt;</content><author><name></name></author><summary type="html">This is an option I had not come across when researching multiplayer environment options back in GAM720. Most information I have found this time around seems to be quite recent, even though it appears to have originally come into being in 2016. This, to me, is a good sign, as it appears to be gaining traction and becoming more relevant as time marches on.</summary></entry><entry><title type="html">Video Streaming</title><link href="http://localhost:4000/2020/07/02/webrtc.html" rel="alternate" type="text/html" title="Video Streaming" /><published>2020-07-02T00:00:00+01:00</published><updated>2020-07-02T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/02/webrtc</id><content type="html" xml:base="http://localhost:4000/2020/07/02/webrtc.html">&lt;h2 id=&quot;webrtc&quot;&gt;WebRTC&lt;/h2&gt;

&lt;p&gt;There is a plugin asset available for Unity that implements WebRTC. An interesting aspect is that the most recent version &lt;a href=&quot;https://docs.unity3d.com/Packages/com.unity.webrtc@2.0/manual/index.html&quot;&gt;supports Vulkan and OpenGL&lt;/a&gt;, so should be compatible with the Quest once built and running in the untethered Android platform. Development using Oculus Link, of course, does not require Vulkan to be supported and WebRTC’s NVIDIA compatibility will suffice for this, which is just as well because the new Unity XR Integration plugin only recently included Vulkan support, and it may be &lt;a href=&quot;https://developer.oculus.com/blog/vulkan-support-for-oculus-quest-in-unity-experimental/#:~:text=In%202019.3%2C%20Unity%20is%20moving,the%20new%20XR%20Management%20system.&quot;&gt;still a little buggy&lt;/a&gt;.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Vulkan support is still in early stages&lt;/strong&gt;
&lt;img src=&quot;\images\GAM750\xr-vulkan-1.JPG&quot; alt=&quot;XR Vulkan support&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;what-is-good-about-webrtc&quot;&gt;What is good about WebRTC?&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Allows direct communication between clients, bypassing the server.&lt;/li&gt;
  &lt;li&gt;Works via UDP, which is excellent for non-important, simple data like video, becuase it does not constantly check if the data is being received.&lt;/li&gt;
  &lt;li&gt;Most browsers support WebRTC and those that don’t such as Microsoft Edge and Safari, are supported with a plugin.&lt;/li&gt;
  &lt;li&gt;Very quick.&lt;/li&gt;
  &lt;li&gt;Google and Facebook use WebRTC. NB - I wonder if the fact that facebook use it will mean great on-going support for Oculus devices?&lt;/li&gt;
  &lt;li&gt;Open source.&lt;/li&gt;
  &lt;li&gt;Many open source libraries available, so many different interfacing possibilities.&lt;/li&gt;
  &lt;li&gt;Secure - encryption is mandatory.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;webrtc-and-unity&quot;&gt;WebRTC and Unity&lt;/h1&gt;
&lt;p&gt;I’m concerned there may be a major hurdle: unless I find out otherwise, or find a way around this issue, it looks as though it may not be possible to stream video &lt;strong&gt;into&lt;/strong&gt; the VR environment. The Unity WebRTC package is intended to provide rendering from Unity into a browser.&lt;/p&gt;

&lt;p&gt;Bearing mind, though, that this is from 2018 and there have been a number of updates since: -&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://forum.unity.com/threads/unity-render-streaming-introduction-faq.742481/&quot;&gt;Unity Render Streaming Introduction &amp;amp; FAQ&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;What is Unity Render Streaming?&lt;/strong&gt;
This is a solution that provides Unity’s high definition rendering abilities via a browser. It’s designed to meet the needs of tasks like viewing car configurators or architectural models on mobile devices.
This solution’s streaming technology takes advantage of WebRTC, and through customization, developers can create their own unique solutions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sam77777 said: Is possible to stream on browser of the VR device and get input from HMD?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;kazuki_unity729 of Unity Technologies said: I am not sure the webrtc technology works on VR devices.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It also appears that video must be served by a PC with a decent NVidia card:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This means there´s a server PC (with a NVidiaCard) running an Executable as a server that streams the video and reacts to the input coming from the mobile devices, right?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Yes&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;asset-webrtc-video-chat&quot;&gt;Asset: &lt;em&gt;WebRTC Video Chat&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;This is an asset in the Unity Asset store by &lt;a href=&quot;https://www.because-why-not.com/webrtc/&quot;&gt;Because why not?&lt;/a&gt; that looks simple to use when connecting various systems (it still may not be compatible with VR or Quest (Android)), but it is quite &lt;a href=&quot;&quot;&gt;expensive&lt;/a&gt; - €102.73.&lt;/p&gt;

&lt;p&gt;But it least it shows streaming directly between two apps is possible. Again, it’s not clear if this can be done in VR.&lt;/p&gt;

&lt;h1 id=&quot;mixedreality-webrtc&quot;&gt;MixedReality-WebRTC&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/microsoft/MixedReality-WebRTC&quot;&gt;Microsoft GitHub repository&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This looks very interesting&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;MixedReality-WebRTC is a collection of libraries to help mixed reality app developers to integrate peer-to-peer real-time audio and video communication into their application and improve their collaborative experience.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;MixedReality-WebRTC is a set of individual building blocks in the form of C and C# libraries building upon each other to deliver a consistent API to C/C++ and C# developers across its supported platforms, and a set of handful drop-in &lt;strong&gt;Unity3D&lt;/strong&gt; components for easy integration.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Open source - MIT license&lt;/li&gt;
  &lt;li&gt;Available as NuGet package&lt;/li&gt;
  &lt;li&gt;Documented: user manual, API reference&lt;/li&gt;
  &lt;li&gt;Maintained by the &lt;a href=&quot;https://github.com/orgs/microsoft/teams/mixed-reality-sharing&quot;&gt;Mixed Reality Sharing team&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://microsoft.github.io/MixedReality-WebRTC/manual/unity/unity-integration.html&quot;&gt;Unity library overview&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://microsoft.github.io/MixedReality-WebRTC/manual/unity/helloworld-unity.html&quot;&gt;Hello, Unity world!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/gam750/mixed-reality-webrtc-1.JPG&quot; alt=&quot;Hello, Unity world&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It seems building for &lt;strong&gt;Android&lt;/strong&gt; is possible:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://microsoft.github.io/MixedReality-WebRTC/manual/building.html&quot;&gt;Building from sources&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://microsoft.github.io/MixedReality-WebRTC/manual/android/building-android.html&quot;&gt;Android&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">WebRTC</summary></entry><entry><title type="html">Video Streaming</title><link href="http://localhost:4000/2020/07/02/video-streaming.html" rel="alternate" type="text/html" title="Video Streaming" /><published>2020-07-02T00:00:00+01:00</published><updated>2020-07-02T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/02/video-streaming</id><content type="html" xml:base="http://localhost:4000/2020/07/02/video-streaming.html">&lt;p&gt;I want to stream video and other media and data into my Unity-created VR experience.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;How can I do this?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Reading around the subject of sockets, both in general and specifically with regard to Unity: -&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h1 id=&quot;webdev&quot;&gt;&lt;a href=&quot;https://web.dev/websocketstream/&quot;&gt;web.dev&lt;/a&gt;&lt;/h1&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API&quot;&gt;WebSocket API&lt;/a&gt;&lt;/strong&gt;: a JavaScript interface using the &lt;strong&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc6455&quot;&gt;WebSocket protocol&lt;/a&gt;&lt;/strong&gt;. &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Opens a two-way open interactive communication session between browser and server. Does not require server polling.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Streams_API&quot;&gt;Streams API&lt;/a&gt;&lt;/strong&gt;: JavaScript API to access streams of data chunks. Reading/writing speed is regulated by the concept of &lt;strong&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Streams_API/Concepts#Backpressure&quot;&gt;backpressure&lt;/a&gt;&lt;/strong&gt;.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The WebSocket API cannot apply backpressure, so can get overwhelmed when messages arrive faster than they can be handled. The solution is the &lt;strong&gt;WebSocketStream API&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h1 id=&quot;stackoverflow&quot;&gt;&lt;a href=&quot;https://stackoverflow.com/questions/42717713/unity-live-video-streaming&quot;&gt;StackOverflow&lt;/a&gt;&lt;/h1&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This person has a minor problem with a solution they have built in Unity. They are sending images, but much of the principle should be the same. Of course, it’s the solution I’m interested in studying.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h1 id=&quot;unity-forum&quot;&gt;&lt;a href=&quot;https://forum.unity.com/threads/stream-video-through-network.464693/&quot;&gt;Unity forum&lt;/a&gt;&lt;/h1&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h1 id=&quot;playing-video-from-url&quot;&gt;&lt;a href=&quot;https://answers.unity.com/questions/1363049/does-videoplayerurl-supports-playing-live-video-fr.html&quot;&gt;Playing video from url&lt;/a&gt;&lt;/h1&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;
&lt;strong&gt;.. continue - there are many more links to go here&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;out-of-the-box-options&quot;&gt;Out-of-the-box options&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://webrtc.org/&quot;&gt;WebRTC&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Open source (so free!)&lt;/li&gt;
  &lt;li&gt;Mature as non-Unity platform&lt;/li&gt;
  &lt;li&gt;Unity package &lt;strong&gt;&lt;em&gt;should&lt;/em&gt;&lt;/strong&gt; work with both Oculus Link (NVIDIA codec) and untethered/Android (Vulkan/OpenGL)&lt;/li&gt;
  &lt;li&gt;Appears to have recently been &lt;a href=&quot;https://blogs.unity3d.com/2019/09/17/stream-high-quality-real-time-graphics-through-your-browser-with-our-new-webrtc-framework/&quot;&gt;embraced by Unity&lt;/a&gt; as their defacto tech in the area of streaming&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.agora.io/en/&quot;&gt;Agora&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Free for low use only&lt;/li&gt;
  &lt;li&gt;Pay As You Go &lt;a href=&quot;https://www.agora.io/en/pricing/&quot;&gt;pricing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Simple to set up&lt;/li&gt;
  &lt;li&gt;Can stream voice and video&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.genvidtech.com/&quot;&gt;Genvid&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Appears to have a functionality set that is close to what could be required.  There is a &lt;a href=&quot;https://www.genvidtech.com/licensing/&quot;&gt;pricing/licensing structure&lt;/a&gt;, that depends on individual unique viewers per month. I’m not quite sure how this would work in the kind of scenario I’m thinking of.&lt;/p&gt;</content><author><name></name></author><summary type="html">I want to stream video and other media and data into my Unity-created VR experience.</summary></entry><entry><title type="html">Multiplayer Options</title><link href="http://localhost:4000/2020/07/01/multiplayer.html" rel="alternate" type="text/html" title="Multiplayer Options" /><published>2020-07-01T10:00:00+01:00</published><updated>2020-07-01T10:00:00+01:00</updated><id>http://localhost:4000/2020/07/01/multiplayer</id><content type="html" xml:base="http://localhost:4000/2020/07/01/multiplayer.html">&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/2020/07/01/photon.html&quot;&gt;Photon PUN2&lt;/a&gt;: as discussed in GAM720&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2020/07/02/mirror.html&quot;&gt;Mirror&lt;/a&gt;: looks very interesting&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Photon PUN2: as discussed in GAM720 Mirror: looks very interesting</summary></entry><entry><title type="html">Photon</title><link href="http://localhost:4000/2020/07/01/photon.html" rel="alternate" type="text/html" title="Photon" /><published>2020-07-01T00:00:00+01:00</published><updated>2020-07-01T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/01/photon</id><content type="html" xml:base="http://localhost:4000/2020/07/01/photon.html">&lt;p&gt;Back at the start of GAM720 I started looking at &lt;strong&gt;&lt;a href=&quot;https://doc.photonengine.com/en-us/pun/current/getting-started/pun-intro&quot;&gt;Photon PUN 2&lt;/a&gt;&lt;/strong&gt; as a way of creating a multiplayer environment in Unity.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Building the multiplayer environment&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/2020/02/09/building-the-multiplayer-environment-part1.html&quot;&gt;Part 1&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/2020/02/12/building-the-multiplayer-environment-part2.html&quot;&gt;Part 2&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This could still be an option for the getting multiple bodies within a single space, where they can interact with each other.&lt;/p&gt;

&lt;p&gt;Streaming video will probably be best done using another solution, whether that be something like WebRTC or a bespoke sockets solution. Sending large amounts of data streaming through the Photon servers will likely present problems, such as speed issues and the potential of bumping up costs. I’d want to remain in the free banding, i.e. &amp;lt; 20 concurrent connections and &amp;lt; 60GB during development and maybe use a self-hosting server once up and running - see &lt;a href=&quot;https://forum.unity.com/threads/photon-pun2-free-forever-or-only-during-the-first-60gb.877201/&quot;&gt;this&lt;/a&gt; discussion.&lt;/p&gt;</content><author><name></name></author><summary type="html">Back at the start of GAM720 I started looking at Photon PUN 2 as a way of creating a multiplayer environment in Unity.</summary></entry><entry><title type="html">Unity XR Integration</title><link href="http://localhost:4000/2020/07/01/unity-xr-integration-update.html" rel="alternate" type="text/html" title="Unity XR Integration" /><published>2020-07-01T00:00:00+01:00</published><updated>2020-07-01T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/01/unity-xr-integration-update</id><content type="html" xml:base="http://localhost:4000/2020/07/01/unity-xr-integration-update.html">&lt;h1 id=&quot;update-i-intend-to-persevere-with-xr-integration&quot;&gt;Update: I intend to persevere with XR Integration&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;.. at least, for now.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;I like the simplicity of the approach. Oculus SDK is somewhat ‘noodly’, requiring many different configurations and components depending on the specific scenario and associated setup. Unity XR appears to be more streamlined in this respect.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;XR will be much more future-proof, with Unity intending on deprecating support for Oculus SDK at some point in the future.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As XR developes over time, my knowledge and understanding will grow with it. I will not need to start at the bottom of a steep learning curve when the target point is fast disappearing over the horizon. I will, hopefully, be within sight of that point throughout the journey.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hand tracking will be incoporated at some point. At the moment I don’t believe I will require it, but I know I will in the future. If I find I need it sooner rather than later, then I can always revert to the Oculus SDK.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Update: I intend to persevere with XR Integration</summary></entry></feed>