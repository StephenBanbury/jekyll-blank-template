<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-07-24T17:47:25+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Creative Reflective Journal</title><subtitle>My Creative Reflective Journal towards the Falmouth University Creative App Development Masters Degree.</subtitle><entry><title type="html">Syncing Data In Normcore 2</title><link href="http://localhost:4000/2020/07/24/normcore-7.html" rel="alternate" type="text/html" title="Syncing Data In Normcore 2" /><published>2020-07-24T00:00:00+01:00</published><updated>2020-07-24T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/24/normcore-7</id><content type="html" xml:base="http://localhost:4000/2020/07/24/normcore-7.html">&lt;h1 id=&quot;success&quot;&gt;Success!&lt;/h1&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-3.1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;And to celebrate..&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore3.2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Success!</summary></entry><entry><title type="html">Syncing Data In Normcore 1</title><link href="http://localhost:4000/2020/07/23/normcore-6.html" rel="alternate" type="text/html" title="Syncing Data In Normcore 1" /><published>2020-07-23T00:00:00+01:00</published><updated>2020-07-23T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/23/normcore-6</id><content type="html" xml:base="http://localhost:4000/2020/07/23/normcore-6.html">&lt;p&gt;I’m setting out here to try to solve the problem of syncing abstract data between two instances in a multiplayer environment.&lt;/p&gt;

&lt;p&gt;The Normcore pattern of keeping gameobjects in sync with a model held in the datastore should, in theory, also work for simple values. Here I’m attempting to find out how to do this.&lt;/p&gt;

&lt;p&gt;I’m looking in particular at the tutorial &lt;strong&gt;&lt;a href=&quot;https://normcore.io/documentation/guides/synchronizing-your-own-data.html&quot;&gt;Synchronizing your own data with custom Realtime Components&lt;/a&gt;&lt;/strong&gt; here for some guidance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;You see the problem…&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-sync-issue-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;A RealtimeComponent keeps a game object in sync with its corresponding model in the datastore. When the game object changes, it updates the model, and when the model changes, it updates the game object to match.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I have already followed the &lt;strong&gt;&lt;a href=&quot;/2020/07/16/normcore-3.html&quot;&gt;Normcore documentation-tutorial&lt;/a&gt;&lt;/strong&gt; on changing the colour of an obect, and I hope to follow a similar pattern here. However, instead of colour, I will use an abstract numerical value. This, I hope, can be the basis of transforming any kind of data, returned from any kind of action, into any other kind of action. I may be over-egging the problem here - it may be simpler than I imagine. But this should at least be a valuable learning excercise!&lt;/p&gt;</content><author><name></name></author><summary type="html">I’m setting out here to try to solve the problem of syncing abstract data between two instances in a multiplayer environment.</summary></entry><entry><title type="html">Multiplayer Made Simple</title><link href="http://localhost:4000/2020/07/22/normcore-5.html" rel="alternate" type="text/html" title="Multiplayer Made Simple" /><published>2020-07-22T00:00:00+01:00</published><updated>2020-07-22T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/22/normcore-5</id><content type="html" xml:base="http://localhost:4000/2020/07/22/normcore-5.html">&lt;p&gt;Building a simple multiplayer is made easy in Normcore.&lt;/p&gt;

&lt;p&gt;This example uses the Oculus OVRPlayerController, but it could just as easily use any other solution, such as the Unity XR integration.&lt;/p&gt;

&lt;p&gt;A Normcore Realtime VR + Player is included in the scene and the OVRPlayerController is wired in as the Local Player variable. That’s all that is required to instantiate the avatar in each multiplayer instance!&lt;/p&gt;

&lt;p&gt;The grabbable object script is also attached to the Realtime VR + Player, and Realtime View and Realtime Transform scripts are added to the grabbable object, along with a simple script that requests ownership of the object - via its Realtime Transform component - when it is grabbed by one of the players. If the Realtime View’s ‘Owned by Creating Client’ is checked then the other player cannot gain ownership.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  private void Update()
{
    if (gameObject.GetComponent&amp;lt;OVRGrabbable&amp;gt;().isGrabbed)
    {
        //potentially clear ownership first - if owned
        _realtimeTransform.RequestOwnership();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;two-players-one-headset&quot;&gt;Two players, one headset!&lt;/h1&gt;

&lt;p&gt;Testing is a bit of a problem of course, with only one Oculus Quest (and only one developer!), both players cannot be independently moved at the same time. But it is possible to see the other player and use one’s imagination! Unfortunately, without two players it is not possible to try out throwing and catching - that would be great fun!&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-2.1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;The sound of the player’s voice is also picked up enabling lipsyncing. I will be looking at ways to stream the voice to other players.&lt;/p&gt;</content><author><name></name></author><summary type="html">Building a simple multiplayer is made easy in Normcore.</summary></entry><entry><title type="html">Normcore 2 Preview</title><link href="http://localhost:4000/2020/07/17/normcore-4.html" rel="alternate" type="text/html" title="Normcore 2 Preview" /><published>2020-07-17T00:00:00+01:00</published><updated>2020-07-17T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/17/normcore-4</id><content type="html" xml:base="http://localhost:4000/2020/07/17/normcore-4.html">&lt;p&gt;I contacted Max Weisel of the Normcore team, via their Discord server, with a question, as I was having trouble getting objects to render in the other client instance - I could just see a horizon. Max responded with the solution (ensure the build is 64bit) in a matter of minutes - very impressive! I mentioned how impressed I am with Normcore and he suggested I contact Nick Savarese - another Normcore team member - to be given access to the Normcore 2 Preview. Apparently, the transitions are significantly smoother.&lt;/p&gt;

&lt;p&gt;This I did, and Nick sent me a message followed by emails with attached Unity projects with the preview versions pre-installed. It’s great to be at the cutting edge!&lt;/p&gt;

&lt;h1 id=&quot;normcore-200-preview-1&quot;&gt;Normcore 2.0.0 Preview 1&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Heyo,&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Thanks for your interest in trying out Normcore 2.0! Most of you are on Normcore 1.0, so we’ll be rolling out Normcore 2.0 features in stages in order to make upgrading as easy as possible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The first preview build is almost identical to the Normcore 1.0 API, however it features a completely new transport system and backend. Latency will be even lower and this backend should be much more stable. We’re currently only running the 2.0 backend on our US clusters. We’ll be bringing all of our regions online in about two weeks.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you’re starting out on a fresh project with Normcore 2.0, you’ll want to import the Unity package without importing the Examples folder first. Then once the package is imported, you can reimport it again if you’d like to bring the examples into the project.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Upgrading from Normcore 1.0
Ensure your project currently compiles, leave all existing Normcore files in place, and backup your project! Then follow these instructions exactly:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Import the unitypackage and wait for it to compile once.&lt;/li&gt;
    &lt;li&gt;After the first compilation, Normcore will be added in Package Manager. Unity will recompile again, and you’ll have a ton of duplicate symbol errors.&lt;/li&gt;
    &lt;li&gt;Delete the Realtime folder under Normal, and your project will start compiling again.&lt;/li&gt;
    &lt;li&gt;All that’s left is to fix any scene or prefabs that reference Normcore components. Go to Window &amp;gt; Normcore &amp;gt; Migrate and wait a few seconds for it to complete.&lt;/li&gt;
    &lt;li&gt;Once migration finishes, you’re good to go!&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Feel free to email us if you have any questions. we’ve also created a #normcore2-preview channel on our discord!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Stay Normal!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;normcore-200-preview-8&quot;&gt;Normcore 2.0.0 Preview 8&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hey everyone,&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;We’ve now deployed the breaking backend change and have pushed an updated Unity package.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;This update also moved a few files around in the Examples folder. If you get an error while updating, please delete the Normal folder, and import the latest Unity package attached here.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you’ve previously migrated RealtimeAvatar/RealtimeAvatarManager scripts in your scenes and prefabs, we’ve moved them back to source files so people can copy them easily. You’ll need to manually migrate them back, or revert to copies of your scenes / prefabs before the migration and run the migration script again.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you’re starting out on a fresh project with Normcore 2.0, you’ll want to import the Unity package without importing the Examples folder first. Then once the package is imported, you can reimport it again if you’d like to bring the examples into the project.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;As always, feel free to email us if you have any questions or hit us up on the #normcore2-preview channel on our discord!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Best,
Nick&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">I contacted Max Weisel of the Normcore team, via their Discord server, with a question, as I was having trouble getting objects to render in the other client instance - I could just see a horizon. Max responded with the solution (ensure the build is 64bit) in a matter of minutes - very impressive! I mentioned how impressed I am with Normcore and he suggested I contact Nick Savarese - another Normcore team member - to be given access to the Normcore 2 Preview. Apparently, the transitions are significantly smoother.</summary></entry><entry><title type="html">Normcore - Feeling Good</title><link href="http://localhost:4000/2020/07/16/normcore-2.html" rel="alternate" type="text/html" title="Normcore - Feeling Good" /><published>2020-07-16T00:00:00+01:00</published><updated>2020-07-16T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/16/normcore-2</id><content type="html" xml:base="http://localhost:4000/2020/07/16/normcore-2.html">&lt;h1 id=&quot;feeling-good-about-normcore&quot;&gt;Feeling good about Normcore&lt;/h1&gt;

&lt;p&gt;Normcore has everything that I imagined I would be spending a significant amount of time building, but packaged up and ready to use. For this reason alone, it is extremely attractive as a means to building a multiplayer environment. I have so far begin exploring the idea of building my own server-client in C# and using TCP and UDP, Photon PUN 2 as an out-of-the-box solution and Mirror as a Unity-integrated and relatively simple way of wiring multiplayer clients together.&lt;/p&gt;

&lt;p&gt;The one thing that sets Normcore apart is that, simply put, it just works - or so it would seem. Particularly  with regard to VR. As a VR mutliplayer developer, the basics have already been done for you. The disadvantage, then is that, if you really do want to get to understand the mechanics of multiplayer networking, of how physics are translated from one client to another etc., these are mainly done by Normcore and it’s less likely you will learn from a deap, low-level perspective.&lt;/p&gt;

&lt;p&gt;Even so, it is still necessary to understand the model that is used by Normcore, and to understand it well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\images\GAM750\normcore-flow-1.jpg&quot; alt=&quot;Normcore data flow&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A RealtimeComponent keeps a game object in sync with its corresponding model in the datastore. When the game object changes, it updates the model, and when the model changes, it updates the game object to match. This means that in the diagram above, when Player 1 moves a game object, RealtimeTransform can set the new position on its model in the datastore. When Player 2 gets a notification that the model changed, it can update the position of the matching game object in its scene&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">Feeling good about Normcore</summary></entry><entry><title type="html">Exploring Normcore</title><link href="http://localhost:4000/2020/07/16/normcore-3.html" rel="alternate" type="text/html" title="Exploring Normcore" /><published>2020-07-16T00:00:00+01:00</published><updated>2020-07-16T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/16/normcore-3</id><content type="html" xml:base="http://localhost:4000/2020/07/16/normcore-3.html">&lt;h1 id=&quot;exploring-normcore-via-tutorials&quot;&gt;Exploring Normcore via tutorials&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;moving body&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-sync-movement.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;avatar&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-sync-avatar.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;syncing colour&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-sync-colour.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Exploring Normcore via tutorials</summary></entry><entry><title type="html">The Project - Not Near Enough</title><link href="http://localhost:4000/2020/07/15/not-near-enough.html" rel="alternate" type="text/html" title="The Project - Not Near Enough" /><published>2020-07-15T00:00:00+01:00</published><updated>2020-07-15T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/15/not-near-enough</id><content type="html" xml:base="http://localhost:4000/2020/07/15/not-near-enough.html">&lt;p&gt;&lt;strong&gt;Not Near Enough&lt;/strong&gt; is a &lt;strong&gt;&lt;a href=&quot;https://www.storyfutures.com/academy&quot;&gt;StoryFutures Academy&lt;/a&gt;&lt;/strong&gt;-funded project at Falmouth University exploring VR theatre spaces.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The brief for this project is to create an adaptable and interactive virtual theatre space where
actors and audience meet. The same space would also function as a teaching and rehearsal
space for Falmouth students and staff.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;During the past week I put together an expression of interest, resulting in an invitation from the team leaders to discuss the possibility of my working on the project. This took place on Monday, and yesterday (Tuesday) I was invited to join the project as &lt;strong&gt;VR Unity Developer&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;notes-from-initial-discussion&quot;&gt;Notes from initial discussion&lt;/h2&gt;

&lt;h1 id=&quot;brief-outline---project-background&quot;&gt;Brief outline - project background&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;StoryFutures Academy&lt;/strong&gt; - one of the government’s appointed ‘creative clusters’. Collaboration between Royal Holloway University of London and National Film and Television School, who are primaritly interested in funding and upskilling businesses and organisations in the West London area in new digital media - VR, AR, XR etc.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Train The Trainer&lt;/strong&gt; is a StoryFutures initiative as part of a funding strand offered to work with universities across the country.&lt;/li&gt;
  &lt;li&gt;Five universities have this funding - Falmouth, Hertfordshire, Abertay, UCL, Bath Spa.&lt;/li&gt;
  &lt;li&gt;The funding is, in this case, to be used for a &lt;strong&gt;‘teaching-led’&lt;/strong&gt; project.&lt;/li&gt;
  &lt;li&gt;Due to the COVID-19 pandemic, this year Falmouth University &lt;strong&gt;AMATA&lt;/strong&gt; (Academy of Music and Theatre Arts) are devising a project that is about creating for an immersive, virtual environment.&lt;/li&gt;
  &lt;li&gt;The view of the directors is that theatre, performance, acting students - those interested in live performance - are better placed to consider such spaces than film and television students, because they are used to working in spaces that happen all around, be they real or virtual.&lt;/li&gt;
  &lt;li&gt;We will be working with &lt;strong&gt;theatre and performance&lt;/strong&gt; students and &lt;strong&gt;technical theatre arts&lt;/strong&gt; students.&lt;/li&gt;
  &lt;li&gt;The students will be engaged in creating content for the environment.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;20&lt;/strong&gt; students in total: &lt;strong&gt;16&lt;/strong&gt; theatre and performance and &lt;strong&gt;4&lt;/strong&gt; technical theatre arts.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-environment&quot;&gt;The environment&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Important: the &lt;strong&gt;‘liveness’&lt;/strong&gt; and &lt;strong&gt;‘interactiveness’&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Visual concept - the &lt;strong&gt;‘varyon’&lt;/strong&gt; - morphs and moves around the audience.&lt;/li&gt;
  &lt;li&gt;As well as images of performers streamed into the environment, they would like some form of &lt;strong&gt;‘volumetric capture’&lt;/strong&gt; if possible, where the performers appear in the space as a kind of &lt;strong&gt;‘hologram’&lt;/strong&gt;, or &lt;strong&gt;‘avatar’&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;This can be incomplete, blocky or outlined etc. - i.e.  not a full perfect representation.&lt;/li&gt;
  &lt;li&gt;Audience will wear headsets&lt;/li&gt;
  &lt;li&gt;Performers streamed in via, for example, cameras or laptops.&lt;/li&gt;
  &lt;li&gt;Interested in how an audience with audience interaction might &lt;em&gt;look like&lt;/em&gt;, how would they be aware of each other’s presence, how will they interact with the space?&lt;/li&gt;
  &lt;li&gt;Audience of approximately 8-10.&lt;/li&gt;
  &lt;li&gt;One idea is to maybe pick four formations created by the screens, and the audience transitions between them via an animation, with each space being seen as an interactive ‘installation’ space.&lt;/li&gt;
  &lt;li&gt;Klaus Kruse (director) outlined possible ideas for ‘flow’ through the space(s).&lt;/li&gt;
  &lt;li&gt;Potential for audience members to split up and explore difference spaces before joining together in a joint &lt;em&gt;‘grand finale’&lt;/em&gt; / &lt;em&gt;‘communal conclusion’&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;There is an awareness of the possible limitations and realisation that not every idea may be possible, or feasible given the time and technical limitations.&lt;/li&gt;
  &lt;li&gt;The animations can be derived from the experience of the way the screens, each of which hinges onto the next, move when the space changes its shape.&lt;/li&gt;
  &lt;li&gt;It would be hoped that the audience can interact with the screens in at least one of the spaces - push, move, realign into different shapes.&lt;/li&gt;
  &lt;li&gt;Live interaction via video so the audience can see and speak with the performers - live feed.&lt;/li&gt;
  &lt;li&gt;This would also mean the space can be used as a live rehearsal space.&lt;/li&gt;
  &lt;li&gt;The audience sees the performer on the screen.&lt;/li&gt;
  &lt;li&gt;Pixelation etc. will be ‘embraced’ and become part of the aesthetic.&lt;/li&gt;
  &lt;li&gt;Students can maybe access the space via 360 degree video displayed on google cardboard via phones.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/GAM750/not-near-enough-perf-map-1.jpg&quot; alt=&quot;performance map&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;research-experimentation-dialogue-and-rd&quot;&gt;Research, experimentation, dialogue and R&amp;amp;D&lt;/h1&gt;

&lt;p&gt;This is very much a dialogue, a collaboration. There is space for me, as a developer to bring to the project. It is likely that, as theatre practitioners, the project devisers and leaders of the project have thought aobut differentely, or have ideas that are not necessarily feasible in the way they imagined them. This project is in many respects, an R&amp;amp;D project - there is a lot of research and experimentation to be done in attempting to realise something that is close to the original concepts.&lt;/p&gt;

&lt;p&gt;There is also the potential for publishing a research paper or two at the end of the project. It this stage, I see this as something I’d be interested in being invovled in.&lt;/p&gt;

&lt;h1 id=&quot;time-scale&quot;&gt;Time scale&lt;/h1&gt;

&lt;p&gt;They would like something ready and working - certainly not complete - during September, or start of October, in order to work with students within the virtual space.&lt;/p&gt;

&lt;h1 id=&quot;collaboration&quot;&gt;Collaboration&lt;/h1&gt;

&lt;p&gt;It was agreed that, should it be necessary or helpful to bring in external expertise as and when necessary, we will do so. I’m thinking potentially in terms of graphics, animations, character or environment aesthetics etc., that this could be a good thing to do.&lt;/p&gt;</content><author><name></name></author><summary type="html">Not Near Enough is a StoryFutures Academy-funded project at Falmouth University exploring VR theatre spaces.</summary></entry><entry><title type="html">Normcore</title><link href="http://localhost:4000/2020/07/13/normcore-1.html" rel="alternate" type="text/html" title="Normcore" /><published>2020-07-13T00:00:00+01:00</published><updated>2020-07-13T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/13/normcore-1</id><content type="html" xml:base="http://localhost:4000/2020/07/13/normcore-1.html">&lt;p&gt;This is potentially the best option of all - if I were to forgoe the build-your-own-networking-solution learning curve I mention in the &lt;strong&gt;&lt;a href=&quot;/2020/07/11/client-server-tutorial.html&quot;&gt;previous post&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Normcore looks to be self-contained, including all the building block APIs to get a fully working multiplayer up and running in a short space of time, much like Photon but, from the looks of it, even simpler to implement. It’s main attraction is that it is particularly geared toward VR/AR, which is a huge part of the work out of the way.&lt;/p&gt;

&lt;p&gt;However, it is less mature than Photon, being currently in Beta. But that makes it nice, fresh and young!&lt;/p&gt;

&lt;p&gt;It is created by &lt;strong&gt;&lt;a href=&quot;https://www.normalvr.com/&quot;&gt;normal&lt;/a&gt;&lt;/strong&gt;, who create VR games themselves. I have been particularly enthral to &lt;strong&gt;&lt;a href=&quot;https://halfandhalf.fun/&quot;&gt;Half+Half&lt;/a&gt;&lt;/strong&gt;. Normcore is the plugin they have build for themselves to build their software. It’s all explained in their &lt;strong&gt;&lt;a href=&quot;https://www.normalvr.com/blog/normcore/&quot;&gt;blog&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We’ve spent the last three years working on Normcore, a Unity plug-in for our own internal use, implementing all the different pieces—state syncing, physics syncing, voice chat, persistence, fast serialization with versioning, delta compression, flow control, and much more. Through this process, we noticed a pattern: Everyone currently needs to implement each of these pieces from scratch.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;…we’ve noticed the VR/AR community is in serious need of good multiplayer support, especially when it comes to voice chat (which we believe is paramount to achieving presence in multiplayer spaces). The VOIP community solved high-quality low-latency voice chat a long time ago, and we’ve incorporated the lessons they’ve learned into how audio works in Normcore&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So… all very, very interesting…&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\normcore-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">This is potentially the best option of all - if I were to forgoe the build-your-own-networking-solution learning curve I mention in the previous post.</summary></entry><entry><title type="html">What Else Is There Out There?</title><link href="http://localhost:4000/2020/07/11/what-is-there-out-there.html" rel="alternate" type="text/html" title="What Else Is There Out There?" /><published>2020-07-11T00:00:00+01:00</published><updated>2020-07-11T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/11/what-is-there-out-there</id><content type="html" xml:base="http://localhost:4000/2020/07/11/what-is-there-out-there.html">&lt;h1 id=&quot;here-i-am-going-to-explore-existing-apps-experiences-games-basically-anything-whatsoever-that-holds-some-level-of-interest-as-an-immersive-interactive-space-for-performance-socialisaing-creating-basically-just-being-in-a-virtual-space-with-other-people-represented-in-virtual-form&quot;&gt;Here I am going to explore existing apps, experiences, games… basically anything whatsoever… that holds some level of interest as an immersive, interactive space for performance, socialisaing, creating.. basically, just ‘being’ in a virtual space with other ‘people’ represented in virtual form.&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;The Under Presents&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Game in the form of a theatre production?&lt;/p&gt;

&lt;p&gt;https://www.youtube.com/watch?v=fSQD8DBLODE&lt;/p&gt;</content><author><name></name></author><summary type="html">Here I am going to explore existing apps, experiences, games… basically anything whatsoever… that holds some level of interest as an immersive, interactive space for performance, socialisaing, creating.. basically, just ‘being’ in a virtual space with other ‘people’ represented in virtual form.</summary></entry><entry><title type="html">C# TCP/UDP Client-Server Tutorial</title><link href="http://localhost:4000/2020/07/11/client-server-tutorial.html" rel="alternate" type="text/html" title="C# TCP/UDP Client-Server Tutorial" /><published>2020-07-11T00:00:00+01:00</published><updated>2020-07-11T00:00:00+01:00</updated><id>http://localhost:4000/2020/07/11/client-server-tutorial</id><content type="html" xml:base="http://localhost:4000/2020/07/11/client-server-tutorial.html">&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLXkn83W0QkfnqsK8I0RAz5AbUxfg3bOQ5&quot;&gt;Tom Weiland C# Networking Tutorials&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This has been a very interesting tutorial. The objective is to build a console app server which connects clients and allows mutliplayer interaction.&lt;/p&gt;

&lt;p&gt;Following the tutorial and coding along are not necessarily easy bedfellows, because it is quite a complex set up. My approach is to follow what I can whilst coding and to later work out what I do not fully understand.&lt;/p&gt;

&lt;p&gt;By the end of the first five installments I have build a server, which allows clients to connect, spawning ‘player’ characters, following their movements so they can be viewed by other connected clients, and then disconnecting when a client closes down or the server closes down.&lt;/p&gt;

&lt;p&gt;After this point I feel I really need to know how to pass data across the socket connection in order to inform other clients, via the server in this case, that something has changed in one of the client’s environments. It seems I need to spawn every object that is included in any kind of interaction. This could potentially  involve lots of spawning, and then lots of data for each type of interaction, being passed across the network and then interpreted by the server before being diseminated to each client. At least, that how I believe it will require setting up, before having undertaking the course installments beyond simply moving a player character around the (so far unlimited) space.&lt;/p&gt;

&lt;p&gt;The question here is, do I need to continue exploring the console server option, in which case, do I need to use a phyics library like &lt;a href=&quot;https://www.youtube.com/redirect?event=video_description&amp;amp;v=qkjr_rv4AIQ&amp;amp;redir_token=QUFFLUhqbEpGMUgxUFpzNW4yLXJUaDVGaTFXai0zRHZMUXxBQ3Jtc0ttYWNEM2VQTHlCQWk1c1E5dXhBaUZHQVp1OTFOOTVTX0tJa1lkek45Sk9vYWJhWU1OeHZfd0Y1Y0VwYm1Jb2l3dnNSeGY2SUhPSm9MS0xqM2FJaXdLemdEeVJvNmtTZXpSU1A0Y3ViWXJpbmpuTlhlcw%3D%3D&amp;amp;q=https%3A%2F%2Fgithub.com%2Fbepu%2Fbepuphysics2&quot;&gt;BepuPhysics&lt;/a&gt;, with the alternative being to move the server code into Unity and use its in-build physics, or have I found a pathway this is actually unnecessarily complex? There is a &lt;strong&gt;lot&lt;/strong&gt; to do - I’ll need to add server-side collisions and work out how to make actions that happen on the client also happen elsewhere.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video style=&quot;width:720px;&quot; autoplay=&quot;&quot; loop=&quot;&quot;&gt;
    &lt;source src=&quot;\media\networking-tcp-udp-1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Woops! Your browser does not support the HTML5 video tag.
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Instead, &lt;strong&gt;can I find a simpler solution?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tom suggests that the reason for this setup is partly to prevent cheating. But what I am doing does not attract cheats ;). Would an alterantive such as Mirror be more appropriate? Mirror at least allows direct client-client communication once the connection has been created via the server.&lt;/p&gt;

&lt;p&gt;Or Photon PUN 2? I found this, which sees to suggest that built-in solutions could work: &lt;a href=&quot;https://sharpcoderblog.com/blog/sync-rigidbodies-over-network-using-pun-2&quot;&gt;Sync Rigidbodies Over Network Using PUN 2&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Oh.. my.. God! Why hast Thou forsaken me?!!!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Both these scenarios mean that I will be bypassing a full inward transfer of networking knowledge and plumping for a relatively easy/soft/lightweight/lazy approach. I would like to fully ‘get it’. But I have time and resource limitations. Perhaps it would be best, as is often the case it seems, to go for the simple option to get it up and running and then get to know the detail and complexity later? I’ve spent the best part of three days (i.e. evenings not spent with the family) on this tutorial… Grrrrrr!&lt;/p&gt;

&lt;h2 id=&quot;normcore&quot;&gt;Normcore&lt;/h2&gt;

&lt;p&gt;I’ve now just come across &lt;strong&gt;&lt;a href=&quot;/2020/07/13/normcore-1.html&quot;&gt;Normcore&lt;/a&gt;&lt;/strong&gt;. This looks to be yet another option…&lt;/p&gt;</content><author><name></name></author><summary type="html">Tom Weiland C# Networking Tutorials</summary></entry></feed>